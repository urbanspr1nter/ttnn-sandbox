{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8665dd0",
   "metadata": {},
   "source": [
    "# ðŸ“ NOTE\n",
    "\n",
    "Unless you have chosen to train with the `fineweb-100m` dataset, training on a CPU for a GPT-2 355M model over 1 billion tokens is simply not a good use of time and resources. \n",
    "\n",
    "For this notebook, we'll leverage **GPU training**. It is _possible_ to do this training on a single GPU within a reasonable amount of time.\n",
    "\n",
    "If you don't have access to a GPU, there are a few good options out there such as:\n",
    "\n",
    "* Lambda Cloud\n",
    "* Fly IO\n",
    "* Linode\n",
    "\n",
    "For this notebook, I used my personal NVIDIA RTX 6000 Ada GPU to train. \n",
    "\n",
    "The amount of VRAM necessary is dependent upon the batch size. If you have an older card, most likely you'll be using anywhere between 1, 2, or 4 for the batch size. Newer cards can leverage `bfloat16` data type and that significantly reduces the memory necessary to train. You can look to have anywhere from a batch size of 8 to 32.\n",
    "\n",
    "My card supports `bfloat16`, and so do most cloud GPUs now. So the code will be written with that assumption. Adjust the `batch_size` variable as needed when appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8dffcc",
   "metadata": {},
   "source": [
    "## Cost of Cloud Training\n",
    "\n",
    "I'll cut to the chase. Maybe this discussion will help with deciding on whether training on the cloud may be worth it for you.\n",
    "\n",
    "### Lambda Cloud\n",
    "\n",
    "* I initially trained on Lambda Cloud with their H100 80GB PCIe offering. Batch size was 1 for $2.49 an hour.\n",
    "* Next with batch size of 4 and seeing a H100 80GB SXM come available, I trained this for $3.49\n",
    "\n",
    "### Local\n",
    "\n",
    "* I also trained on my own personal RTX 6000 Ada GPU. Batch size 1\n",
    "* Then I trained again on RTX 6000 Ada GPU with batch size 4\n",
    "\n",
    "### Linode CPU\n",
    "\n",
    "Here's why you should _never_ attempt CPU training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf40f64",
   "metadata": {},
   "source": [
    "# Pretraining 2 - GPT-2 355M - GPU Training\n",
    "\n",
    "I've included the training script `model_train.py` at the same level of this notebook. It is the script I had actually used to produce the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424b96a",
   "metadata": {},
   "source": [
    "## Loading the Input and Validation Tokens\n",
    "\n",
    "We created the dataloaders in the previous notebook. Let's load them back up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "842fce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'fineweb-100m'\n",
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f6b3f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "if device.startswith(\"cuda\"):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8b9088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train_loader.\n",
      "Loaded val_loader\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1786, 316)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.preload_dataloaders import load_pickled_dataloader\n",
    "\n",
    "train_loader = load_pickled_dataloader(f\"data/{dataset_name}/train_loader.dl\")\n",
    "print(\"Loaded train_loader.\")\n",
    "\n",
    "val_loader = load_pickled_dataloader(f\"data/{dataset_name}/val_loader.dl\")\n",
    "print(\"Loaded val_loader\")\n",
    "\n",
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06090699",
   "metadata": {},
   "source": [
    "Validate for the maximum token ID. This makes sure that we don't have any token IDs out of range. Being out of range means that our dataloader could be corrupted. I ended up having to do this because I had bad data in the previous notebook, causing re-do of the loader construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1fad6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum token ID: 50255\n"
     ]
    }
   ],
   "source": [
    "# To check token ID range in your dataset\n",
    "max_token = float('-inf')\n",
    "for i, (input_batch, _) in enumerate(train_loader):\n",
    "    max_token = max(max_token, input_batch.max().item())\n",
    "\n",
    "print(f\"Maximum token ID: {max_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff79635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.gpt2_model import GPTModel\n",
    "\n",
    "GPT_CONFIG_355M = {\n",
    "  \"vocab_size\": 50257,   # Vocabulary size\n",
    "  \"context_length\": 1024, # Context length\n",
    "  \"emb_dim\": 1024,        # Embedding dimension (larger than 124M)\n",
    "  \"n_heads\": 16,         # Number of attention heads (larger than 124M)\n",
    "  \"n_layers\": 24,        # Number of layers (larger than 124M)\n",
    "  \"drop_rate\": 0.0,      # Dropout rate\n",
    "  \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "model = GPTModel(GPT_CONFIG_355M)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4babf",
   "metadata": {},
   "source": [
    "## Existing Training and Validation Loss\n",
    "\n",
    "If you're somehow reloading a model, it's useful to check out the current training and validaton loss. Warning, this will perform a forward pass on all your data, so it is still an expensive effort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0d8bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 11.008848857879638\n",
      "Validation loss: 11.006040573120117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from scripts.train import calc_loss_loader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# use the num_batches parameter to limit the number of batches processed\n",
    "# 20/2 should be enough to tell us something.\n",
    "with torch.no_grad():\n",
    "  train_loss = calc_loss_loader(train_loader, model, device=device, num_batches=20)\n",
    "  val_loss = calc_loss_loader(val_loader, model, device=device, num_batches=2)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "\n",
    "gc.collect()\n",
    "if device.startswith(\"cuda\"):\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5326261",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now it is time to train our 355M model. Running this script n the notebook is actually not a good thing to do. It will take took long. I have included 2 scripts you can run within a `tmux` session so that you can disconnect from your session while still having your training continue. \n",
    "\n",
    "* `model_train.py`\n",
    "* `model_inference.py`.\n",
    "\n",
    "In `train_model_simple`, I have modified the code to take in a `device` argument now to accommodate a GPU. This cause a ripple effect of adding the arguments elswhere. \n",
    "\n",
    "Additionally, I included a new `max_iters` argument to only train the model up to a specific number of steps as an entire epoch would take too long if just needing to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06facdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modern CUDA device found. Using tensor cores.\n",
      "Ep 1 (Step 000000 of 1786): Train loss 9.850, Val loss 9.863\n",
      "Every effort moves you,.  Oprah prizes. , SG thebourg, the,, the Gy, hugged. the Brigham, the,. the Chocobo a, and, Support the. Oprah is reinforces, disarm.1973 a the the,Re,. the\n",
      "Ep 1 (Step 000100 of 1786): Train loss 6.884, Val loss 6.862\n",
      "Every effort moves you do you have a whole. This. All I do I don't. In this you have it and it. Iâ€œSo there can be a very it is not only. When you feel and then you and all: \n",
      "Max iterations exceeded at 100 steps. Max: 100 steps\n",
      "Took this long to train: 159652.69017219543 ms\n",
      "Train losses\n",
      "\n",
      "[9.85, 6.884375]\n",
      "Val losses\n",
      "\n",
      "[9.8625, 6.8625]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from scripts.perf_timer import PerfTimer\n",
    "from scripts.train import train_model_simple\n",
    "from scripts.gpt2_model import GPTModel\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Configure the device\n",
    "if device.startswith(\"cuda\"):\n",
    "  capability = torch.cuda.get_device_capability()\n",
    "  if capability[0] >= 7:\n",
    "    print(\"Modern CUDA device found. Using tensor cores.\")\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "  else:\n",
    "    print(\"Tensor cores not supported on this CPU. Will still proceed.\")\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_355M)\n",
    "\n",
    "# Move model to device BEFORE compiling\n",
    "if device.startswith(\"cuda\"):\n",
    "  torch.cuda.empty_cache()\n",
    "  model = model.to(device).to(torch.bfloat16)\n",
    "else:\n",
    "  model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "  model.parameters(),\n",
    "  lr=2e-4,\n",
    "  weight_decay=0.1,\n",
    "  fused=True\n",
    ")\n",
    "\n",
    "# We have lots of data, so we can just train for a single epoch.\n",
    "num_epochs = 1\n",
    "\n",
    "timer = PerfTimer()\n",
    "\n",
    "timer.start()\n",
    "train_losses, val_losses = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=100,\n",
    "    eval_iter=10, # eval less frequently\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    max_iter=100\n",
    ")\n",
    "timer.stop()\n",
    "\n",
    "print(f\"Took this long to train: {timer.elapsed_ms()} ms\")\n",
    "print(\"Train losses\\n\")\n",
    "print(train_losses)\n",
    "print(\"Val losses\\n\")\n",
    "print(val_losses)\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "if device.startswith(\"cuda\"):\n",
    "  torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259b160",
   "metadata": {},
   "source": [
    "## Save the model \n",
    "\n",
    "Oh, we should save our precious efforts! Let's not make all that waiting all for nothing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab5d64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-355M-100M-test-model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1afadf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"models/{model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160a2841",
   "metadata": {},
   "source": [
    "## Reload the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0439fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19103bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): GPTModel(\n",
       "    (tok_emb): Embedding(50257, 1024)\n",
       "    (pos_emb): Embedding(1024, 1024)\n",
       "    (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "    (trf_blocks): Sequential(\n",
       "      (0): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (6): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (7): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (8): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (9): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (10): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (11): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (12): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (13): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (14): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (15): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (16): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (17): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (18): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (19): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (20): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (21): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (22): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (23): TransformerBlock(\n",
       "        (att): MultiHeadAttention(\n",
       "          (W_query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (W_value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (layer): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU()\n",
       "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_norm): LayerNorm()\n",
       "    (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.model_loader import load_model_from_path\n",
    "\n",
    "model = load_model_from_path(\n",
    "    f'models/{model_name}',\n",
    "    device\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da881d7",
   "metadata": {},
   "source": [
    "## Testing by inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d45f4ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated tokens in 23413.634061813354 ms\n",
      "Output text:\n",
      " Every effort moves you can do me and their first, a good and to the whole with a new to keep a real of the right at the time that to the idea to have, you are the other.\n",
      "â€™s a large and are not going to the\n"
     ]
    }
   ],
   "source": [
    "from scripts.perf_timer import PerfTimer\n",
    "from scripts.generate import generate\n",
    "from scripts.text_helpers import text_to_token_ids, token_ids_to_text\n",
    "\n",
    "perf_timer = PerfTimer()\n",
    "\n",
    "# Create input tokens directly on the correct device to avoid compilation issues\n",
    "input_ids = text_to_token_ids(\"Every effort moves you\", tokenizer).to(device)\n",
    "\n",
    "perf_timer.start()\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=input_ids,\n",
    "    max_new_tokens=50,\n",
    "    context_size=GPT_CONFIG_355M[\"context_length\"],\n",
    "    temperature=1.0,\n",
    "    top_k=25,\n",
    "    device=device\n",
    ")\n",
    "perf_timer.stop()\n",
    "\n",
    "print(\"Generated tokens in\", perf_timer.elapsed_ms(), \"ms\")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855735f",
   "metadata": {},
   "source": [
    "## Analyzing the Results\n",
    "\n",
    "- Talk about starting training and validation loss\n",
    "- Talk about the end\n",
    "- Chart the data after grabbing the entire arrays (I printed them out)\n",
    "- Mention that 3B dataset for the 355M model for 1 epoch at the learning rate I was going is probably too little... But good to test our hypothesis.\n",
    "- I didn't save the optimizer, so now I am in a situation where a second epoch has to start with an optimizer without any momentum\n",
    "- Still worth doing a second epoch in that state - I will just increase the learning rate by 3x to get to where i need to go faster -- plus, my model is somewhat stable at this point. (momentum means additional delta determined from past gradients off from the direction we're going)\n",
    "\n",
    "## Next steps to get a quality model\n",
    "- Epoch 2 - on 3B dataset, increased learning rate to account for lack of optimizer saving\n",
    "- Build a 10B dataset and train a version of the 355M model. (Chinchilla scaling law -> 7B tokens is optimal in general)\n",
    "\n",
    "Lastly! Save the optimizer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700819e9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
