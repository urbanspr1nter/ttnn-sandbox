{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8665dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cf40f64",
   "metadata": {},
   "source": [
    "# Pretraining GPT-2 Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424b96a",
   "metadata": {},
   "source": [
    "## Loading the Input and Validation Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b9088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.preload_dataloaders import load_train_dataloader, load_val_dataloader\n",
    "\n",
    "train_loader = load_train_dataloader(\"data/fineweb-3b/train_loader.dl\")\n",
    "print(\"Loaded train_loader.\")\n",
    "\n",
    "val_loader = load_val_dataloader(\"data/fineweb-3b/val_loader.dl\")\n",
    "print(\"Loaded val_loader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff79635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.gpt2_model import GPTModel\n",
    "\n",
    "GPT_CONFIG_355M = {\n",
    "  \"vocab_size\": 50257,   # Vocabulary size\n",
    "  \"context_length\": 1024, # Context length\n",
    "  \"emb_dim\": 1024,        # Embedding dimension (larger than 124M)\n",
    "  \"n_heads\": 16,         # Number of attention heads (larger than 124M)\n",
    "  \"n_layers\": 24,        # Number of layers (larger than 124M)\n",
    "  \"drop_rate\": 0.0,      # Dropout rate\n",
    "  \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_355M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d8bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train import calc_loss_loader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loss = calc_loss_loader(train_loader, model)\n",
    "val_loss = calc_loss_loader(val_loader, model)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5326261",
   "metadata": {},
   "source": [
    "Now it is time to train our 355M model. Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06facdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.perf_timer import PerfTimer\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_355M)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "# We have lots of data, so we can just train for a single epoch.\n",
    "num_epochs = 1\n",
    "\n",
    "timer = PerfTimer()\n",
    "\n",
    "timer.start()\n",
    "train_losses, val_losses = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=50, # eval less frequently\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "timer.stop()\n",
    "\n",
    "print(f\"Took this long to train: {timer.elapsed_ms()} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259b160",
   "metadata": {},
   "source": [
    "## Save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afadf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/gpt2-355M-model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160a2841",
   "metadata": {},
   "source": [
    "## Reload the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19103bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scripts.gpt2_model import GPTModel\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_355M)\n",
    "model.load_state_dict(\n",
    "  torch.load(\"models/gpt2-355M-model.pth\", weights_only=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da881d7",
   "metadata": {},
   "source": [
    "## Testing by inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f4ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.perf_timer import PerfTimer\n",
    "from scripts.generate import generate_text_simple\n",
    "\n",
    "perf_timer = PerfTimer()\n",
    "\n",
    "perf_timer.start()\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=GPT_CONFIG_355M[\"context_length\"]\n",
    ")\n",
    "perf_timer.stop()\n",
    "\n",
    "print(\"Generated tokens in\", perf_timer.elapsed_ms(), \"ms\")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
