{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "511ed556-c30c-4ce3-8163-84475bd3cdca",
   "metadata": {},
   "source": [
    "# tt-NN Embedding Layer Example\n",
    "\n",
    "This notebook shows how you can create an embedding layer out of `ttnn` tensors. \n",
    "\n",
    "The techniques in this notebook are adapted from [Sebastian Raschka](https://github.com/rasbt)'s [LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch) repository. Please check it out. He is a huge inspiration for the work in this repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c482db-8a68-4157-ba8e-150c497aca28",
   "metadata": {},
   "source": [
    "## What are Embeddings?\n",
    "\n",
    "Embeddings are special tensors which record information about a context of tokens. We have 2 types:\n",
    "1. **Token embeddings** - Records the information necessary to take a token and form a word within context -- \"What kind of word is this?\"\n",
    "2. **Positional embeddings** - Information about a token and the relationship between the other tokens in context to the position for its window. -- \"Where does this word sit in the sentence?\"\n",
    "\n",
    "Both of these contain trainable weights in which will be adjusted during training. \n",
    "\n",
    "We won't train them separately, we'll create and use **input embeddings** to do this. This is the sum of the token and positional embedding tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672b7ca-2a85-463a-a464-18a9608acd10",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d0b07-b252-4674-bce8-e6e5c766d31f",
   "metadata": {},
   "source": [
    "Let's assume we are developing a GPT-2 LLM model. We will need to specify a `vocab_size` and `output_dim`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39a0d34-57ef-478e-8985-eadaeab2d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f938c80-1221-456b-b8d3-84c5ea6e75c8",
   "metadata": {},
   "source": [
    "Next, let's import some dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63223398-3da0-43e3-9ff4-ef0af4313377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 16:35:21.539 | DEBUG    | ttnn:<module>:83 - Initial ttnn.CONFIG:\n",
      "Config{cache_path=/home/avgdev/.cache/ttnn,model_cache_path=/home/avgdev/.cache/ttnn/models,tmp_dir=/tmp/ttnn,enable_model_cache=false,enable_fast_runtime_mode=true,throw_exception_on_fallback=false,enable_logging=false,enable_graph_report=false,enable_detailed_buffer_report=false,enable_detailed_tensor_report=false,enable_comparison_mode=false,comparison_mode_should_raise_exception=false,comparison_mode_pcc=0.9999,root_report_path=generated/ttnn/reports,report_name=std::nullopt,std::nullopt}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ttnn\n",
    "from scripts.prepare_data import create_dataloader_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cc017-d537-4d37-b715-6f0f381b7608",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Let's build a simple dataset by first acquiring some text. We will use a short story called `the-verdict.txt`. You can find it in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c82783-8481-4bae-a68e-a431a2634575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap g\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(raw_text[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5da5903-bea7-47a9-8ed8-0041cb00d178",
   "metadata": {},
   "source": [
    "Next, let's create a dataloader so that we can obtain some batches. We'll assume a:\n",
    "\n",
    "* context length of 4\n",
    "* batch size of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1d6eb2-376a-4586-8a95-ebb44a4c4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 4\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ca11c-bf1d-43e4-a0ce-3d90d0283b93",
   "metadata": {},
   "source": [
    "Note we'll just return a single input and target batch for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33aaddda-1232-4853-83ad-b9aa0c89f6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   40,   367,  2885,  1464],\n",
       "         [ 1807,  3619,   402,   271],\n",
       "         [10899,  2138,   257,  7026],\n",
       "         [15632,   438,  2016,   257],\n",
       "         [  922,  5891,  1576,   438],\n",
       "         [  568,   340,   373,   645],\n",
       "         [ 1049,  5975,   284,   502],\n",
       "         [  284,  3285,   326,    11]]),\n",
       " tensor([[  367,  2885,  1464,  1807],\n",
       "         [ 3619,   402,   271, 10899],\n",
       "         [ 2138,   257,  7026, 15632],\n",
       "         [  438,  2016,   257,   922],\n",
       "         [ 5891,  1576,   438,   568],\n",
       "         [  340,   373,   645,  1049],\n",
       "         [ 5975,   284,   502,   284],\n",
       "         [ 3285,   326,    11,   287]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=batch_size, max_length=context_length,\n",
    "    stride=context_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad08603-f2a8-45e1-9268-69541c92e888",
   "metadata": {},
   "source": [
    "## Torch Example\n",
    "\n",
    "First, in `torch`, we can typically create input embeddings by creating a token embedding layer, and positional embedding layer concatenated together. \n",
    "\n",
    "The token embedding layer receives the input batch, and the positional embedding can be initialized to increasing numbers. \n",
    "Once we create the embedding layers with `torch.nn.Embedding`, we just pass in those inputs to get the embeddings.\n",
    "\n",
    "With `torch`, it is pretty simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6f765f-d5e0-4040-89b1-57e8fbeb85e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.7318, -0.1439,  0.5758,  ..., -0.5013,  0.4811,  1.0332],\n",
      "         [-0.3948, -0.2520,  0.0813,  ..., -2.9140, -0.7542, -2.5006],\n",
      "         [-1.6651,  1.4861,  2.0051,  ..., -1.8440, -2.2303,  1.8921],\n",
      "         [ 0.4186, -0.7514,  0.0198,  ..., -0.0732, -0.5632, -1.1741]],\n",
      "\n",
      "        [[ 1.5556,  0.5127, -0.7803,  ..., -0.8864, -1.2456,  0.7119],\n",
      "         [ 1.0383, -2.5513,  0.6281,  ..., -0.2517, -0.9386, -1.7914],\n",
      "         [-0.5865, -0.8332, -0.6496,  ..., -1.4694, -1.5772,  2.8228],\n",
      "         [-0.9811, -0.3645, -0.1702,  ..., -1.7683, -1.6742, -2.0518]]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "\n",
    "positional_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "positional_embeddings = positional_embedding_layer(torch.arange(context_length))\n",
    "\n",
    "input_embeddings = token_embeddings + positional_embeddings\n",
    "\n",
    "print(input_embeddings[0:2])\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c61576-cc58-43fe-8358-d772d59f7ae2",
   "metadata": {},
   "source": [
    "## tt-NN Example\n",
    "\n",
    "Unfortunately life isn't as easy with `ttnn`, but we can get to the same place. \n",
    "\n",
    "Let's create the token embeddings and positional embeddings one-by-one and we can combine them to create the input_embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a4b106-c527-473f-a66e-357162201719",
   "metadata": {},
   "source": [
    "### Device Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2fb9e4-a1ec-48bf-ba4c-410fb6cba9cd",
   "metadata": {},
   "source": [
    "Various operations require the tensors to be on the device. So let's initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae488bc8-56e1-453e-b94b-382492bf8ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Device | INFO     | Opening user mode device driver\n",
      "\u001b[32m2025-04-19 16:35:27.562\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\n",
      "\u001b[32m2025-04-19 16:35:27.574\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-04-19 16:35:27.575\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Harvesting mask for chip 0 is 0x200 (physical layout: 0x1, logical: 0x200, simulated harvesting mask: 0x0).\n",
      "\u001b[32m2025-04-19 16:35:27.576\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-04-19 16:35:27.577\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected PCI devices: [0]\n",
      "\u001b[32m2025-04-19 16:35:27.577\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using local chip ids: {0} and remote chip ids {}\n",
      "\u001b[32m2025-04-19 16:35:27.604\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Software version 6.0.0, Ethernet FW version 6.14.0 (Device 0)\n",
      "                  Metal | INFO     | Initializing device 0. Program cache is NOT enabled\n",
      "                  Metal | INFO     | AI CLK for device 0 is:   1000 MHz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New chip! We now have 1 chips\n",
      "Chip initialization complete (found )\n",
      "Chip initializing complete...\n",
      " ARC\n",
      "\n",
      " [4/4] DRAM\n",
      "\n",
      " [16/16] ETH\n",
      "\n",
      " CPU\n",
      "\n",
      "Chip detection complete (found )\n"
     ]
    }
   ],
   "source": [
    "device_id = 0 \n",
    "device = ttnn.open_device(device_id=device_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc0675-cb94-4b3a-bc29-446dd9e435be",
   "metadata": {},
   "source": [
    "### Creating Token Embeddings\n",
    "\n",
    "We can first start by creating the token embeddings. Let's turn the `inputs` and `targets` batches into `ttnn` tensors. We'll also need to send them to the device to operate on. Note that `ttnn.embedding` is an on-device storage operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007ddf27-191a-4ab9-87e7-8054c4d6df1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ttnn.Tensor([[   40,   367,  ...,  2885,  1464],\n",
       "              [ 1807,  3619,  ...,   402,   271],\n",
       "              ...,\n",
       "              [ 1049,  5975,  ...,   284,   502],\n",
       "              [  284,  3285,  ...,   326,    11]], shape=Shape([8, 4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR),\n",
       " ttnn.Tensor([[  367,  2885,  ...,  1464,  1807],\n",
       "              [ 3619,   402,  ...,   271, 10899],\n",
       "              ...,\n",
       "              [ 5975,   284,  ...,   502,   284],\n",
       "              [ 3285,   326,  ...,    11,   287]], shape=Shape([8, 4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_ttnn = ttnn.from_torch(inputs, dtype=ttnn.uint32)\n",
    "targets_ttnn = ttnn.from_torch(targets, dtype=ttnn.uint32)\n",
    "\n",
    "inputs_ttnn = ttnn.to_device(inputs_ttnn, device)\n",
    "targets_ttnn = ttnn.to_device(targets_ttnn, device)\n",
    "\n",
    "inputs_ttnn, targets_ttnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c19e3b-6a28-469b-ab1d-4945508c99aa",
   "metadata": {},
   "source": [
    "Creating an embedding tensor is more involved. We will need to **initialize a weight tensor** that has the dimensions of the vocabularly size and output dimensions.\n",
    "\n",
    "These will just be consisted of random values.\n",
    "\n",
    "The dimensions end up being (50257, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66a7ec89-bd7d-4ccf-a7c4-ff891891474f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[ 0.34961, -1.04688,  ...,  0.87891, -1.46094],\n",
       "             [-0.50781,  1.07031,  ..., -0.66406,  0.47266],\n",
       "             ...,\n",
       "             [ 1.10938,  0.14355,  ...,  0.62109, -0.98828],\n",
       "             [-1.05469, -1.05469,  ...,  0.89844, -0.83594]], shape=Shape([50257, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding_weights_ttnn = ttnn.from_torch(\n",
    "    torch.randn(vocab_size, output_dim),\n",
    "    dtype=ttnn.bfloat16\n",
    ")\n",
    "token_embedding_weights_ttnn = ttnn.to_device(token_embedding_weights_ttnn, device)\n",
    "\n",
    "token_embedding_weights_ttnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb36dec-3051-4ec0-ad48-f938956be700",
   "metadata": {},
   "source": [
    "Now we can create the token_embeddings in one shot with `ttnn.embedding`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7670a363-746d-48d6-9295-cf207ac51c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[[-1.40625, -1.02344,  ..., -0.03613, -1.40625],\n",
       "              [-0.37500,  0.01392,  ..., -0.21094,  0.23145],\n",
       "              ...,\n",
       "              [-0.83594,  0.66016,  ...,  0.87500, -0.70312],\n",
       "              [-1.28125,  0.89062,  ...,  0.42969, -1.62500]],\n",
       "\n",
       "             [[-0.16406,  0.17676,  ...,  2.42188,  1.03906],\n",
       "              [-0.41992,  0.38281,  ..., -0.97266,  0.30859],\n",
       "              ...,\n",
       "              [-0.87500,  0.83594,  ...,  0.16602,  1.04688],\n",
       "              [ 0.23535,  1.66406,  ...,  1.26562,  0.95312]],\n",
       "\n",
       "             ...,\n",
       "\n",
       "             [[-1.01562,  1.47656,  ...,  0.32617,  0.09131],\n",
       "              [ 1.32031,  1.08594,  ...,  0.89844, -0.38086],\n",
       "              ...,\n",
       "              [ 0.15820, -0.81641,  ...,  3.28125,  0.35938],\n",
       "              [ 1.33594, -0.01080,  ..., -0.02966,  0.33789]],\n",
       "\n",
       "             [[ 0.15820, -0.81641,  ...,  3.28125,  0.35938],\n",
       "              [-0.10352, -0.69141,  ..., -0.30664, -0.83594],\n",
       "              ...,\n",
       "              [-0.66016,  0.60938,  ..., -0.57031,  1.05469],\n",
       "              [ 0.06641,  1.69531,  ..., -1.63281, -0.32812]]], shape=Shape([8, 4, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings_ttnn = ttnn.embedding(inputs_ttnn, token_embedding_weights_ttnn)\n",
    "token_embeddings_ttnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad45b28-7959-43b2-a60f-c1ac56a3dd50",
   "metadata": {},
   "source": [
    "### Creating Positional Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c28f14-73c9-4f52-be35-6c1f60920435",
   "metadata": {},
   "source": [
    "We can repeat the same thing with positional embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac65bd-1514-43f0-9cd4-241fda3727fb",
   "metadata": {},
   "source": [
    "We'll need to generate some positional inputs first. We'll create a simple tensor from 0 to the context_length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c93d15a6-3fd9-4ab3-8073-8548d71a00e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([    0,     1,  ...,     2,     3], shape=Shape([4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_inputs_ttnn = ttnn.arange(end=context_length, dtype=ttnn.uint32)\n",
    "positional_inputs_ttnn = ttnn.to_device(positional_inputs_ttnn, device)\n",
    "\n",
    "positional_inputs_ttnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a86fc4-70b9-44d4-82ed-15c6d4522aff",
   "metadata": {},
   "source": [
    "Now we can create positional embedding weights. These are random again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63411ea3-a073-4486-9b09-d2c263cb0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_embeddings_weights = ttnn.from_torch(\n",
    "    torch.randn(context_length, output_dim),\n",
    "    dtype=ttnn.bfloat16\n",
    ")\n",
    "positional_embeddings_weights = ttnn.to_device(positional_embeddings_weights, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596aa8e7-ee2c-4a3d-9e31-027d9cbd53c9",
   "metadata": {},
   "source": [
    "Create positional embeddings now using the positional inputs and the randomly initialized positional embeddings weights. This ends up being a tensor that is (4, 256)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88c213c7-a665-40b5-b802-9f5fe2fea44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[-2.01562, -1.32812,  ..., -2.21875, -1.43750],\n",
       "             [-1.62500,  1.10938,  ...,  0.36523, -1.01562],\n",
       "             ...,\n",
       "             [ 0.81250,  0.24512,  ..., -0.35742, -0.33789],\n",
       "             [-0.72266, -0.08984,  ...,  0.77734,  0.66797]], shape=Shape([4, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_embeddings_ttnn = ttnn.embedding(positional_inputs_ttnn, positional_embeddings_weights)\n",
    "positional_embeddings_ttnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f8cd3c-59d3-401f-bac9-1abd105a6804",
   "metadata": {},
   "source": [
    "We're not quite done with the positional_embeddings_ttn yet. We have to now reshape for addition operation coming up. This involves:\n",
    "1. Reshape the `positional_embeddings_ttnn` tensor to be the same number of dimensions as the `token_embeddings_ttn`. In this case we go from (4, 256) to (1, 4, 256).\n",
    "2. However, the process in step 1 only results in operating in a batch size of 1. So we need to \"broadcast\" by using `repeat_interleave` to make an effective addition broadcast across all elements in the tensor when added against the `token_embeddings_ttnn`\n",
    "\n",
    "It is expected that we turn the (4, 246) shape into a (8, 4, 256) shape tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae17dc5f-2d3c-4b70-9a96-bf5efd5d8728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[[-2.01562, -1.32812,  ..., -2.21875, -1.43750],\n",
       "              [-1.62500,  1.10938,  ...,  0.36523, -1.01562],\n",
       "              ...,\n",
       "              [ 0.81250,  0.24512,  ..., -0.35742, -0.33789],\n",
       "              [-0.72266, -0.08984,  ...,  0.77734,  0.66797]],\n",
       "\n",
       "             [[-2.01562, -1.32812,  ..., -2.21875, -1.43750],\n",
       "              [-1.62500,  1.10938,  ...,  0.36523, -1.01562],\n",
       "              ...,\n",
       "              [ 0.81250,  0.24512,  ..., -0.35742, -0.33789],\n",
       "              [-0.72266, -0.08984,  ...,  0.77734,  0.66797]],\n",
       "\n",
       "             ...,\n",
       "\n",
       "             [[-2.01562, -1.32812,  ..., -2.21875, -1.43750],\n",
       "              [-1.62500,  1.10938,  ...,  0.36523, -1.01562],\n",
       "              ...,\n",
       "              [ 0.81250,  0.24512,  ..., -0.35742, -0.33789],\n",
       "              [-0.72266, -0.08984,  ...,  0.77734,  0.66797]],\n",
       "\n",
       "             [[-2.01562, -1.32812,  ..., -2.21875, -1.43750],\n",
       "              [-1.62500,  1.10938,  ...,  0.36523, -1.01562],\n",
       "              ...,\n",
       "              [ 0.81250,  0.24512,  ..., -0.35742, -0.33789],\n",
       "              [-0.72266, -0.08984,  ...,  0.77734,  0.66797]]], shape=Shape([8, 4, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_embeddings_ttnn = ttnn.reshape(positional_embeddings_ttnn, (1, context_length, output_dim))\n",
    "positional_embeddings_ttnn = ttnn.repeat_interleave(positional_embeddings_ttnn, repeats=batch_size, dim=0)\n",
    "positional_embeddings_ttnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abb4fa-effd-4b7d-a7d6-2f920d3d8637",
   "metadata": {},
   "source": [
    "### Create the Input Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a85924e-ded5-468b-8d9b-6833f13eb5cd",
   "metadata": {},
   "source": [
    "We can now compute the input_embeddings with token_embeddings_tttn and positional_embeddings_ttn. \n",
    "Operating on device memory requires us to reshape the layout of the tensors to be tile. (32x32)\n",
    "\n",
    "Since we have a small context length and batch size, notice that there will be lots of padding as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42b6f779-c024-47ad-b0e2-e54b5a73c43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: reader_unary_stick_layout_split_rows_interleaved\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: writer_unary_interleaved_start_id, reader_unary_stick_layout_split_rows_interleaved, tilize\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[[-3.42188, -2.35938,  ..., -2.25000, -2.84375],\n",
       "              [-2.00000,  1.12500,  ...,  0.15430, -0.78516],\n",
       "              ...,\n",
       "              [-0.02344,  0.90625,  ...,  0.51953, -1.03906],\n",
       "              [-2.00000,  0.80078,  ...,  1.21094, -0.95703]],\n",
       "\n",
       "             [[-1.26562, -3.09375,  ...,  1.38281, -0.95703],\n",
       "              [-1.02344, -0.21094,  ...,  2.89062, -0.38281],\n",
       "              ...,\n",
       "              [ 0.18359, -0.84766,  ..., -2.31250,  0.03906],\n",
       "              [ 1.93750, -0.82031,  ..., -2.03125, -0.38281]],\n",
       "\n",
       "             ...,\n",
       "\n",
       "             [[ 0.65625, -0.04297,  ..., -0.37500,  2.81250],\n",
       "              [-1.14062,  0.32812,  ..., -1.21875, -1.89062],\n",
       "              ...,\n",
       "              [-0.91406, -0.10400,  ..., -0.59766,  1.80469],\n",
       "              [-0.22168, -0.62500,  ...,  2.34375, -1.57031]],\n",
       "\n",
       "             [[ 1.13281,  0.16016,  ...,  0.67578, -0.67969],\n",
       "              [ 1.95312,  0.13672,  ..., -0.08105,  0.01709],\n",
       "              ...,\n",
       "              [ 0.16602, -1.05469,  ...,  0.64453, -1.80469],\n",
       "              [-1.47656,  2.46875,  ..., -1.73438, -2.42188]]], shape=Shape([8, 4, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings_ttnn = ttnn.add(\n",
    "    ttnn.tilize(token_embeddings_ttnn),\n",
    "    ttnn.tilize(positional_embeddings_ttnn)\n",
    ")\n",
    "input_embeddings_ttnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d4a849-7353-486b-a686-5b05c9f1a345",
   "metadata": {},
   "source": [
    "Thre's a lot of padding inserted, which is why you will see extreme values at the end of the tensors. We can untilize to get back the data in a view that looks better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d5a8760-7be8-4b50-8c32-8bd16cb57329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: reader_unary_interleaved_start_id\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[[-3.42188, -2.35938,  ..., -2.25000, -2.84375],\n",
       "              [-2.00000,  1.12500,  ...,  0.15430, -0.78516],\n",
       "              ...,\n",
       "              [-0.02344,  0.90625,  ...,  0.51953, -1.03906],\n",
       "              [-2.00000,  0.80078,  ...,  1.21094, -0.95703]],\n",
       "\n",
       "             [[-2.18750, -1.14844,  ...,  0.20312, -0.39844],\n",
       "              [-2.04688,  1.49219,  ..., -0.60938, -0.70703],\n",
       "              ...,\n",
       "              [-0.06250,  1.07812,  ..., -0.19141,  0.71094],\n",
       "              [-0.48828,  1.57812,  ...,  2.04688,  1.62500]],\n",
       "\n",
       "             ...,\n",
       "\n",
       "             [[-3.03125,  0.14844,  ..., -1.89062, -1.34375],\n",
       "              [-0.30469,  2.20312,  ...,  1.26562, -1.39844],\n",
       "              ...,\n",
       "              [ 0.97266, -0.57031,  ...,  2.92188,  0.02148],\n",
       "              [ 0.61328, -0.10059,  ...,  0.74609,  1.00781]],\n",
       "\n",
       "             [[-1.85938, -2.14062,  ...,  1.06250, -1.07812],\n",
       "              [-1.72656,  0.41797,  ...,  0.05859, -1.85156],\n",
       "              ...,\n",
       "              [ 0.15234,  0.85547,  ..., -0.92969,  0.71875],\n",
       "              [-0.65625,  1.60938,  ..., -0.85547,  0.33984]]], shape=Shape([8, 4, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: writer_unary_stick_layout_split_rows_interleaved, reader_unary_interleaved_start_id, pack_untilize\n"
     ]
    }
   ],
   "source": [
    "input_embeddings_ttnn = ttnn.untilize(input_embeddings_ttnn)\n",
    "input_embeddings_ttnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6716f2f9-690e-4ae2-a68a-fe952961a21e",
   "metadata": {},
   "source": [
    "Let's do a sanity check. We're expecting the same (8, 4, 256) shape.\n",
    "\n",
    "This means a batch_size of 8, with 4 tokens in context, for 256 dimensions. The greater the dimensions the more \"detail\" we will have to record the embeddings for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86f77ece-59bc-42d2-9354-a1cd66720dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttnn.Tensor([[[-3.42188, -2.35938,  ..., -2.25000, -2.84375],\n",
      "              [-2.00000,  1.12500,  ...,  0.15430, -0.78516],\n",
      "              ...,\n",
      "              [-0.02344,  0.90625,  ...,  0.51953, -1.03906],\n",
      "              [-2.00000,  0.80078,  ...,  1.21094, -0.95703]],\n",
      "\n",
      "             [[-1.26562, -3.09375,  ...,  1.38281, -0.95703],\n",
      "              [-1.02344, -0.21094,  ...,  2.89062, -0.38281],\n",
      "              ...,\n",
      "              [ 0.18359, -0.84766,  ..., -2.31250,  0.03906],\n",
      "              [ 1.93750, -0.82031,  ..., -2.03125, -0.38281]]], shape=Shape([2, 4, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)\n",
      "Shape([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "print(input_embeddings_ttnn[0:2])\n",
    "print(input_embeddings_ttnn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd38db-dad3-4d26-8366-676349a20edd",
   "metadata": {},
   "source": [
    "Finally, don't forget to clean up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f37eecf-bd16-4159-9491-9cad676696bc",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "331df0f7-a4ee-4ef4-a312-e68d2b001079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Metal | INFO     | Closing device 0\n",
      "                  Metal | INFO     | Disabling and clearing program cache on device 0\n"
     ]
    }
   ],
   "source": [
    "ttnn.close_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497af35-6235-4f20-a790-f792f076c433",
   "metadata": {},
   "source": [
    "## ðŸš€ DONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb064cb-10be-4e04-9385-ef45942ee38a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
