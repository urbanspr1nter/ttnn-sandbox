{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5eda073",
   "metadata": {},
   "source": [
    "# Pretraining GPT2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808561cb",
   "metadata": {},
   "source": [
    "We shorten the context length because our data set doesn't have enough tokens for the original 1024 context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.0,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0647de",
   "metadata": {},
   "source": [
    "## Torch Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4cf5b6",
   "metadata": {},
   "source": [
    "Import the libraries, and now we have separated the `GPTModel` implementation to a new file to make the notebook smaller, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from scripts.gpt2_model import GPTModel\n",
    "\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda4e337",
   "metadata": {},
   "source": [
    "We will just instantiate the model. Since our config already has 0 drop out, we don't need to turn on `eval` mode for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da393ec9",
   "metadata": {},
   "source": [
    "Define some helpers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.generate import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639330fd",
   "metadata": {},
   "source": [
    "Let's test the model at the moment. Again we expect it to generate some garbage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70abd679",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "  model=model,\n",
    "  idx=text_to_token_ids(start_context, tokenizer),\n",
    "  max_new_tokens=10,\n",
    "  context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae6ae2",
   "metadata": {},
   "source": [
    "## Loss Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75dbead",
   "metadata": {},
   "source": [
    "we have 2 batches here, so we add the corresponding \"next\" token into the targets while maintaining a consistent context length. this gives a \"sliding window\" effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4aa20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]\n",
    "\n",
    "inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c2157",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e811430",
   "metadata": {},
   "source": [
    "Probas contains for each token, there are vocab_size probabilities in the last dimension. We want to select the token ID (the index) of the highest number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32814b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f8d56",
   "metadata": {},
   "source": [
    "For each word, we find an individual token to succeed the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a4a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a4869",
   "metadata": {},
   "source": [
    "But too bad! we're nowhere close to our target!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4708dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "\n",
    "print(f\"Targets batch 2: {token_ids_to_text(targets[1], tokenizer)}\")\n",
    "print(f\"Outputs batch 2: {token_ids_to_text(token_ids[1].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a0dfa2",
   "metadata": {},
   "source": [
    "So what did this probabilities look like for the _real_ indices for targets? You'll find them to be small. The goal now is to increase these probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df0a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289da65",
   "metadata": {},
   "source": [
    "Take the log for individual probabilities and then concatenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833da750",
   "metadata": {},
   "source": [
    "Take the average and negate to make it positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b2d99",
   "metadata": {},
   "source": [
    "The above is basically what we call \"cross entropy loss\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a6310",
   "metadata": {},
   "source": [
    "## Cross Entropy\n",
    "\n",
    "Lets just use torch cross_entropy to do everything we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c07811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abec1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea174aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2ca81b",
   "metadata": {},
   "source": [
    "We can calculate the perplexity too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480caa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99233a6",
   "metadata": {},
   "source": [
    "## Data Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa747d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/the-verdict.txt\", \"r\") as f:\n",
    "  text_data = f.read()\n",
    "\n",
    "text_data[:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce841e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.prepare_data import create_dataloader_v1\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93645756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a59bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee348934",
   "metadata": {},
   "source": [
    "Given the input and targets, we forward pass through the model for the input batch. Then given the logits, we flatten on the dimensions and calculate the cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f211f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model):\n",
    "    input_batch, target_batch = input_batch, target_batch\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_loss_loader(data_loader, model, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae4e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "train_loss = calc_loss_loader(train_loader, model)\n",
    "val_loss = calc_loss_loader(val_loader, model)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc886e",
   "metadata": {},
   "source": [
    "## Training!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, eval_iter):\n",
    "    train_loss = calc_loss_loader(train_loader, model, num_batches=eval_iter)\n",
    "    val_loss = calc_loss_loader(val_loader, model, num_batches=eval_iter)\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, start_context):\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer)\n",
    "    token_ids = generate_text_simple(\n",
    "        model=model, idx=encoded,\n",
    "        max_new_tokens=50, context_size=context_size\n",
    "    )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20673ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.perf_timer import PerfTimer\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "timer = PerfTimer()\n",
    "\n",
    "timer.start()\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "timer.stop()\n",
    "\n",
    "print(f\"Took this long to train: {timer.elapsed_ms()} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60346ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from scripts.generate import generate_text_simple\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf9e9a",
   "metadata": {},
   "source": [
    "## Saving the Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6713c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/gpt2-verdict-model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874af154",
   "metadata": {},
   "source": [
    "## Reload the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e3036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scripts.gpt2_model import GPTModel\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(\n",
    "  torch.load(\"models/gpt2-verdict-model.pth\", weights_only=True)\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff565267",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8951d6a",
   "metadata": {},
   "source": [
    "## TTNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92299a29",
   "metadata": {},
   "source": [
    "We are not going to train the model using TTNN, instead, we will use it to perform inference in an already trained model. In this case, we diligently trained the GP2 model with our data set using CPU and had saved it to disk. We can reload those weights and reapply them to the GPTModel_ttnn class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b422547b",
   "metadata": {},
   "source": [
    "Redefine the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94daf579",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.0,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c18867",
   "metadata": {},
   "source": [
    "Set some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4a5ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 21:17:36.042 | DEBUG    | ttnn.library_tweaks:prepare_dir_as_metal_home:54 - Existing installation of 0.57.0rc60+any detected\n",
      "2025-05-11 21:17:36.067 | DEBUG    | ttnn:<module>:83 - Initial ttnn.CONFIG:\n",
      "Config{cache_path=/home/avgdev/.cache/ttnn,model_cache_path=/home/avgdev/.cache/ttnn/models,tmp_dir=/tmp/ttnn,enable_model_cache=false,enable_fast_runtime_mode=true,throw_exception_on_fallback=false,enable_logging=false,enable_graph_report=false,enable_detailed_buffer_report=false,enable_detailed_tensor_report=false,enable_comparison_mode=false,comparison_mode_should_raise_exception=false,comparison_mode_pcc=0.9999,root_report_path=generated/ttnn/reports,report_name=std::nullopt,std::nullopt}\n"
     ]
    }
   ],
   "source": [
    "import ttnn\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch import nn\n",
    "from scripts.text_helpers import text_to_token_ids, token_ids_to_text\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "device = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d55b4",
   "metadata": {},
   "source": [
    "## Open the Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633217a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Device | INFO     | Opening user mode device driver\n",
      "\u001b[32m2025-05-11 21:17:37.071\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\n",
      "\u001b[32m2025-05-11 21:17:37.094\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-05-11 21:17:37.097\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Harvesting mask for chip 0 is 0x200 (physical layout: 0x1, logical: 0x200, simulated harvesting mask: 0x0).\n",
      "\u001b[32m2025-05-11 21:17:37.098\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-05-11 21:17:37.099\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected PCI devices: [0]\n",
      "\u001b[32m2025-05-11 21:17:37.099\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using local chip ids: {0} and remote chip ids {}\n",
      "\u001b[32m2025-05-11 21:17:37.123\u001b[0m | \u001b[1m\u001b[3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New chip! We now have 1 chips\n",
      "Chip initialization complete (found )\n",
      "Chip initializing complete...\n",
      " ARC\n",
      "\n",
      " [4/4] DRAM\n",
      "\n",
      " [16/16] ETH\n",
      "\n",
      " CPU\n",
      "\n",
      "Chip detection complete (found )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Software version 6.0.0, Ethernet FW version 6.14.0 (Device 0)\n",
      "                  Metal | INFO     | Initializing device 0. Program cache is NOT enabled\n",
      "                  Metal | INFO     | AI CLK for device 0 is:   1000 MHz\n",
      "                  Metal | INFO     | Enabling program cache on device 0\n"
     ]
    }
   ],
   "source": [
    "if device:\n",
    "  ttnn.close_device(device)\n",
    "\n",
    "device_id = 0\n",
    "device = ttnn.open_device(device_id=device_id)\n",
    "\n",
    "device.enable_program_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ebc5ab",
   "metadata": {},
   "source": [
    "## Initialize the GPT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db15bd6",
   "metadata": {},
   "source": [
    "We will reload the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e3a222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.gpt2_model import GPTModel\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(\n",
    "  torch.load(\"models/gpt2-verdict-model.pth\", weights_only=True)\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae32e7c",
   "metadata": {},
   "source": [
    "What we can do now is reload weights into our model_ttnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1f1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.gpt2_model_ttnn import GPTModel_ttnn, TransformerBlock_ttnn\n",
    "\n",
    "model_ttnn = GPTModel_ttnn(GPT_CONFIG_124M, device)\n",
    "\n",
    "model_ttnn.pos_emb.weight = torch.nn.Parameter(model.pos_emb.weight) \n",
    "model_ttnn.tok_emb.weight = torch.nn.Parameter(model.tok_emb.weight)\n",
    "\n",
    "for i, block in enumerate(model.trf_blocks):\n",
    "  t = model_ttnn.trf_blocks_ttnn[i]\n",
    "\n",
    "  t.att.W_key.weight = torch.nn.Parameter(block.att.W_key.weight)\n",
    "  t.att.W_key.bias = torch.nn.Parameter(block.att.W_key.bias)\n",
    "\n",
    "  t.att.W_query.weight = torch.nn.Parameter(block.att.W_query.weight)\n",
    "  t.att.W_query.bias = torch.nn.Parameter(block.att.W_query.bias)\n",
    "  \n",
    "  t.att.W_value.weight = torch.nn.Parameter(block.att.W_value.weight)\n",
    "  t.att.W_value.bias = torch.nn.Parameter(block.att.W_value.bias)\n",
    "  \n",
    "  t.att.out_proj.weight = torch.nn.Parameter(block.att.out_proj.weight)\n",
    "  t.att.out_proj.bias = torch.nn.Parameter(block.att.out_proj.bias)\n",
    "\n",
    "  t.ff.lin_1.weight = torch.nn.Parameter(block.ff.layer[0].weight)\n",
    "  t.ff.lin_1.bias = torch.nn.Parameter(block.ff.layer[0].bias)\n",
    "  t.ff.lin_2.weight = torch.nn.Parameter(block.ff.layer[2].weight)\n",
    "  t.ff.lin_2.bias = torch.nn.Parameter(block.ff.layer[2].bias)\n",
    "\n",
    "  t.norm1.scale = torch.nn.Parameter(block.norm1.scale)\n",
    "  t.norm1.shift = torch.nn.Parameter(block.norm1.shift)\n",
    "\n",
    "  t.norm2.scale = torch.nn.Parameter(block.norm2.scale)\n",
    "  t.norm2.shift = torch.nn.Parameter(block.norm2.shift)\n",
    "\n",
    "model_ttnn.final_norm.shift = torch.nn.Parameter(model.final_norm.shift)\n",
    "model_ttnn.final_norm.scale = torch.nn.Parameter(model.final_norm.scale)\n",
    "model_ttnn.out_head.weight = torch.nn.Parameter(model.out_head.weight)\n",
    "\n",
    "model_ttnn.update_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a5be5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Shape([50257, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ttnn.tok_emb_ttnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f8a2e",
   "metadata": {},
   "source": [
    "## Compare Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f38852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Status: ✅ PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_diff': 0.0,\n",
       " 'mean_diff': 0.0,\n",
       " 'correlation': 1.0,\n",
       " 'max_diff_status': True,\n",
       " 'mean_diff_status': True,\n",
       " 'correlation_status': True,\n",
       " 'overall_status': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.compare_tensors import compare_tensors\n",
    "\n",
    "compare_tensors(\n",
    "  ttnn.to_torch(\n",
    "    ttnn.reshape(\n",
    "      (model_ttnn.tok_emb_ttnn),\n",
    "      (1, model_ttnn.tok_emb_ttnn.shape[0], model_ttnn.tok_emb_ttnn.shape[1])\n",
    "    )\n",
    "  ),\n",
    "  model.tok_emb.weight.unsqueeze(0),\n",
    "  suppress_details=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de76db",
   "metadata": {},
   "source": [
    "## Compare Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f68c17c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Status: ✅ PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_diff': 0.0,\n",
       " 'mean_diff': 0.0,\n",
       " 'correlation': 0.99609375,\n",
       " 'max_diff_status': True,\n",
       " 'mean_diff_status': True,\n",
       " 'correlation_status': True,\n",
       " 'overall_status': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.compare_tensors import compare_tensors\n",
    "\n",
    "compare_tensors(\n",
    "  ttnn.to_torch(\n",
    "    ttnn.reshape(\n",
    "      (model_ttnn.pos_emb_ttnn),\n",
    "      (1, model_ttnn.pos_emb_ttnn.shape[0], model_ttnn.pos_emb_ttnn.shape[1])\n",
    "    )\n",
    "  ),\n",
    "  model.pos_emb.weight.unsqueeze(0),\n",
    "  suppress_details=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4e389",
   "metadata": {},
   "source": [
    "## Compare Final Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3a6bd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "\n",
      "Overall Status: ✅ PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_diff': 0.0,\n",
       " 'mean_diff': 0.0,\n",
       " 'correlation': 1.0078125,\n",
       " 'max_diff_status': True,\n",
       " 'mean_diff_status': True,\n",
       " 'correlation_status': True,\n",
       " 'overall_status': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.compare_tensors import compare_tensors\n",
    "\n",
    "final_norm_shift_shape = model_ttnn.final_norm.shift_ttnn.shape\n",
    "final_norm_scale_shape = model_ttnn.final_norm.scale_ttnn.shape\n",
    "\n",
    "compare_tensors(\n",
    "  ttnn.to_torch(\n",
    "    ttnn.reshape(\n",
    "      model_ttnn.final_norm.shift_ttnn,\n",
    "      (1, 1, final_norm_shift_shape[0])\n",
    "    )\n",
    "  ),\n",
    "  model.final_norm.shift.unsqueeze(0).unsqueeze(0),\n",
    "  suppress_details=True\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "compare_tensors(\n",
    "  ttnn.to_torch(\n",
    "    ttnn.reshape(\n",
    "      model_ttnn.final_norm.scale_ttnn,\n",
    "      (1, 1, final_norm_scale_shape[0])\n",
    "    )\n",
    "  ),\n",
    "  model.final_norm.scale.unsqueeze(0).unsqueeze(0),\n",
    "  suppress_details=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd955a",
   "metadata": {},
   "source": [
    "## Out Head Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df5f33a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape([50257, 768])\n",
      "\n",
      "Overall Status: ✅ PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_diff': 0.0,\n",
       " 'mean_diff': 0.0,\n",
       " 'correlation': 1.0,\n",
       " 'max_diff_status': True,\n",
       " 'mean_diff_status': True,\n",
       " 'correlation_status': True,\n",
       " 'overall_status': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.compare_tensors import compare_tensors\n",
    "\n",
    "out_head_shape = model_ttnn.out_head_ttnn.shape\n",
    "print(out_head_shape)\n",
    "\n",
    "compare_tensors(\n",
    "  ttnn.to_torch(\n",
    "    ttnn.reshape(\n",
    "      model_ttnn.out_head_ttnn,\n",
    "      (1, out_head_shape[0], out_head_shape[1])\n",
    "    )\n",
    "  ),\n",
    "  model.out_head.weight.unsqueeze(0),\n",
    "  suppress_details=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b274e049",
   "metadata": {},
   "source": [
    "## Transformer Blocks Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "680dcf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n",
      "\n",
      "Overall Status: ✅ PASS\n"
     ]
    }
   ],
   "source": [
    "from scripts.compare_tensors import compare_tensors\n",
    "\n",
    "for i, block in enumerate(model.trf_blocks):\n",
    "  t = model_ttnn.trf_blocks_ttnn[i]\n",
    "\n",
    "  compare_tensors(\n",
    "    ttnn.to_torch(\n",
    "      ttnn.reshape(\n",
    "        t.att.W_key_ttnn,\n",
    "        (1, t.att.W_key_ttnn.shape[0], t.att.W_key_ttnn.shape[1]))\n",
    "    ),\n",
    "    model.trf_blocks[i].att.W_key.weight.unsqueeze(0),\n",
    "    suppress_details=True\n",
    "  )\n",
    "  compare_tensors(\n",
    "    ttnn.to_torch(\n",
    "      ttnn.reshape(\n",
    "        t.att.W_query_ttnn,\n",
    "        (1, t.att.W_query_ttnn.shape[0], t.att.W_query_ttnn.shape[1]))\n",
    "    ),\n",
    "    model.trf_blocks[i].att.W_query.weight.unsqueeze(0),\n",
    "    suppress_details=True\n",
    "  )\n",
    "  compare_tensors(\n",
    "    ttnn.to_torch(\n",
    "      ttnn.reshape(\n",
    "        t.att.W_value_ttnn,\n",
    "        (1, t.att.W_value_ttnn.shape[0], t.att.W_value_ttnn.shape[1]))\n",
    "    ),\n",
    "    model.trf_blocks[i].att.W_value.weight.unsqueeze(0),\n",
    "    suppress_details=True\n",
    "  )\n",
    "  compare_tensors(\n",
    "    ttnn.to_torch(\n",
    "      ttnn.reshape(\n",
    "        t.att.out_proj_ttnn,\n",
    "        (1, t.att.out_proj_ttnn.shape[0], t.att.out_proj_ttnn.shape[1]))\n",
    "    ),\n",
    "    model.trf_blocks[i].att.out_proj.weight.unsqueeze(0),\n",
    "    suppress_details=True\n",
    "  )\n",
    "  compare_tensors(\n",
    "    ttnn.to_torch(\n",
    "      ttnn.reshape(\n",
    "        t.att.out_proj_bias_ttnn,\n",
    "        (1, 1, t.att.out_proj_bias_ttnn.shape[0]))\n",
    "    ),\n",
    "    model.trf_blocks[i].att.out_proj.bias.unsqueeze(0).unsqueeze(0),\n",
    "    suppress_details=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0247d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape([1, 4])\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: reader_unary_pad_dims_split_rows_multicore\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: writer_unary_interleaved_start_id, reader_unary_pad_dims_split_rows_multicore, tilize\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 2,3. First unused index: 1. Kernels: reader_unary_reduce_interleaved_start_id\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 2,3. First unused index: 1. Kernels: writer_unary_interleaved_start_id, reader_unary_reduce_interleaved_start_id, reduce_w\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 2. First unused index: 1. Kernels: reader_unary_interleaved_start_id\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 2. First unused index: 1. Kernels: writer_unary_interleaved_start_id, reader_unary_interleaved_start_id, eltwise_sfpu\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: reader_unary_transpose_wh_interleaved_start_id\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: writer_unary_interleaved_start_id, reader_unary_transpose_wh_interleaved_start_id, transpose_wh\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 4,5. First unused index: 2. Kernels: reader_bmm_tile_layout_in1_sender_writer_padding, reader_bmm_tile_layout_in0_receiver, bmm_large_block_zm_fused_bias_activation\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 4,5. First unused index: 2. Kernels: reader_bmm_tile_layout_in1_sender_writer_padding, reader_bmm_tile_layout_in0_sender_padding, bmm_large_block_zm_fused_bias_activation\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: reader_unary_interleaved_start_id\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: writer_unary_stick_layout_split_rows_multicore, reader_unary_interleaved_start_id, untilize\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 4,5. First unused index: 2. Kernels: reader_writer_bmm_tile_layout_in1, reader_bmm_tile_layout_in0, bmm_large_block_zm_fused_bias_activation\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: writer_unary_stick_layout_split_rows_multicore, reader_unary_interleaved_start_id, pack_untilize\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 2,5,6,7,11. First unused index: 1. Kernels: writer_unary_interleaved_start_id_blocked_sm, reader_unary_interleaved_sm, softmax\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: reader_unary_interleaved_wh_multicore\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: writer_unary_stick_layout_wh_multicore, reader_unary_interleaved_wh_multicore, untilize_wh\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: reader_unary_pad_multicore_both_dims\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: writer_unary_interleaved_start_id_wh, reader_unary_pad_multicore_both_dims, tilize_wh\n",
      "ttnn.Tensor([[ 1.95312,  0.57031,  ..., -3.06250, -4.40625]], shape=Shape([1, 50257]), dtype=DataType::BFLOAT16, layout=Layout::TILE)\n",
      "Shape([1, 50257])\n",
      "ttnn.Tensor([[ 0.00064,  0.00016,  ...,  0.00000,  0.00000]], shape=Shape([1, 50257]), dtype=DataType::BFLOAT16, layout=Layout::TILE)\n",
      "Shape([1, 50257])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "TT_FATAL @ /work/ttnn/cpp/ttnn/operations/reduction/argmax/device/argmax_op.cpp:47: input_shape[0] == 1\ninfo:\ndim 0 must be 1\nbacktrace:\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0xf2f318) [0x7e76b1d2f318]\n --- ttnn::operations::reduction::ArgMax::validate_with_output_tensors(std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&) const\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(_ZN4ttnn16device_operation6detail23launch_on_worker_threadIN2tt8tt_metal9operation23OldInfraDeviceOperationINSt3__16vectorINS4_6TensorENS7_9allocatorIS9_EEEEEENS3_3stl10StrongTypeIhNS_10QueueIdTagEEElNS5_15DeviceOperationISC_EENSD_13tensor_args_tESC_PNS4_7IDeviceEEEvT0_T1_RKT2_RKT3_RT4_RT5_+0x23e) [0x7e76b3e07cde]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(_ZN4ttnn16device_operation6detail23launch_on_single_deviceIN2tt8tt_metal9operation23OldInfraDeviceOperationINSt3__16vectorINS4_6TensorENS7_9allocatorIS9_EEEEEEEENT_21tensor_return_value_tENS3_3stl10StrongTypeIhNS_10QueueIdTagEEERKNSE_22operation_attributes_tERKNSE_13tensor_args_tE+0x83) [0x7e76b3e079f3]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x30078ea) [0x7e76b3e078ea]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(_ZN4ttnn16device_operation6detail6invokeIN2tt8tt_metal9operation23OldInfraDeviceOperationINSt3__16vectorINS4_6TensorENS7_9allocatorIS9_EEEEEEEENT_21tensor_return_value_tENS3_3stl10StrongTypeIhNS_10QueueIdTagEEERKNSE_22operation_attributes_tERKNSE_13tensor_args_tE+0x197) [0x7e76b3e072a7]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x3006c5b) [0x7e76b3e06c5b]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x300693b) [0x7e76b3e0693b]\n --- std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> tt::tt_metal::operation::run<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>(tt::tt_metal::operation::DeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>&&, std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&, tt::stl::StrongType<unsigned char, ttnn::QueueIdTag>)\n --- ttnn::operations::reduction::ArgMaxOperation::invoke(tt::stl::StrongType<unsigned char, ttnn::QueueIdTag>, tt::tt_metal::Tensor const&, std::__1::optional<int>, std::__1::optional<CoreRangeSet> const&, bool, std::__1::optional<tt::tt_metal::MemoryConfig> const&, std::__1::optional<tt::tt_metal::Tensor>)\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156b40b) [0x7e76b236b40b]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156aeb5) [0x7e76b236aeb5]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156abdd) [0x7e76b236abdd]\n --- void tt::tt_metal::operation::launch_op_func<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>(std::__1::function<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> (std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&)> const&, std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>, std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>>, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>>)\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156a4b0) [0x7e76b236a4b0]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x1569e7f) [0x7e76b2369e7f]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x15697d4) [0x7e76b23697d4]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x155bb23) [0x7e76b235bb23]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x155b89a) [0x7e76b235b89a]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0xecbfa9) [0x7e76b1ccbfa9]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x119c33) [0x7e76ded19c33]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_MakeTpCall+0x92) [0x7e76deccb422]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce0aa) [0x7e76decce0aa]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x13c5da) [0x7e76ded3c5da]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_Call+0x5d) [0x7e76deccb1bd]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x4b88) [0x7e76dec701c8]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_FastCallDictTstate+0x6b) [0x7e76deccb57b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_Call_Prepend+0x110) [0x7e76deccb8c0]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x13c608) [0x7e76ded3c608]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_MakeTpCall+0x92) [0x7e76deccb422]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x7559) [0x7e76dec72b99]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x6857) [0x7e76dec71e97]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyEval_EvalCode+0xd2) [0x7e76dedc5962]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1be6d1) [0x7e76dedbe6d1]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a421) [0x7e76ded1a421]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x7e76dec71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe239e) [0x7e76dece239e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xd5a0d) [0x7e76decd5a0d]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x7e76dec71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce050) [0x7e76decce050]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyVectorcall_Call+0xd0) [0x7e76deccb080]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x4b88) [0x7e76dec701c8]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce050) [0x7e76decce050]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x6857) [0x7e76dec71e97]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so(+0x9c11) [0x7e76dd28fc11]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so(+0xa7af) [0x7e76dd2907af]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a00e) [0x7e76ded1a00e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1dc74b) [0x7e76deddc74b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a299) [0x7e76ded1a299]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x4b88) [0x7e76dec701c8]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce050) [0x7e76decce050]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x7518) [0x7e76dec72b58]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyEval_EvalCode+0xd2) [0x7e76dedc5962]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1be6d1) [0x7e76dedbe6d1]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a421) [0x7e76ded1a421]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x7e76dec71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x7e76dec71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x22e06a) [0x7e76dee2e06a]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(Py_RunMain+0x362) [0x7e76dee2e622]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(Py_BytesMain+0x5e) [0x7e76dee2f02e]\n --- /lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7e76de82a1ca]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m tiktoken\u001b[38;5;241m.\u001b[39mget_encoding(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m inputs_ttnn \u001b[38;5;241m=\u001b[39m ttnn\u001b[38;5;241m.\u001b[39mfrom_torch(\n\u001b[1;32m      8\u001b[0m   text_to_token_ids(start_context, tokenizer),\n\u001b[1;32m      9\u001b[0m   layout\u001b[38;5;241m=\u001b[39mttnn\u001b[38;5;241m.\u001b[39mTILE_LAYOUT,\n\u001b[1;32m     10\u001b[0m   dtype\u001b[38;5;241m=\u001b[39mttnn\u001b[38;5;241m.\u001b[39muint32,\n\u001b[1;32m     11\u001b[0m   device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text_simple_ttnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_ttnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m  \u001b[49m\u001b[43midx_ttnn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_ttnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m  \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGPT_CONFIG_124M\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, token_ids_to_text(token_ids, tokenizer))\n",
      "File \u001b[0;32m~/code/ttnn-sandbox/notebooks/scripts/generate_ttnn.py:36\u001b[0m, in \u001b[0;36mgenerate_text_simple_ttnn\u001b[0;34m(model, idx_ttnn, max_new_tokens, context_size, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#probas = torch.softmax(logits, dim=-1)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#idx_next = torch.argmax(probas, dim=-1, keepdim=True)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Convert to row major layout first\u001b[39;00m\n\u001b[1;32m     32\u001b[0m probas_row_major \u001b[38;5;241m=\u001b[39m ttnn\u001b[38;5;241m.\u001b[39mto_layout(\n\u001b[1;32m     33\u001b[0m   probas_ttnn,\n\u001b[1;32m     34\u001b[0m   layout\u001b[38;5;241m=\u001b[39mttnn\u001b[38;5;241m.\u001b[39mROW_MAJOR_LAYOUT\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 36\u001b[0m idx_next \u001b[38;5;241m=\u001b[39m \u001b[43mttnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobas_row_major\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midx_next shape after argmax:\u001b[39m\u001b[38;5;124m\"\u001b[39m, idx_next\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Reshape to ensure we have a 2D tensor with shape [batch_size, 1]\u001b[39;00m\n",
      "File \u001b[0;32m~/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/decorators.py:333\u001b[0m, in \u001b[0;36mFastOperation.__call__\u001b[0;34m(self, *function_args, **function_kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mfunction_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunction_kwargs):\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunction_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunction_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: TT_FATAL @ /work/ttnn/cpp/ttnn/operations/reduction/argmax/device/argmax_op.cpp:47: input_shape[0] == 1\ninfo:\ndim 0 must be 1\nbacktrace:\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0xf2f318) [0x7e76b1d2f318]\n --- ttnn::operations::reduction::ArgMax::validate_with_output_tensors(std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&) const\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(_ZN4ttnn16device_operation6detail23launch_on_worker_threadIN2tt8tt_metal9operation23OldInfraDeviceOperationINSt3__16vectorINS4_6TensorENS7_9allocatorIS9_EEEEEENS3_3stl10StrongTypeIhNS_10QueueIdTagEEElNS5_15DeviceOperationISC_EENSD_13tensor_args_tESC_PNS4_7IDeviceEEEvT0_T1_RKT2_RKT3_RT4_RT5_+0x23e) [0x7e76b3e07cde]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(_ZN4ttnn16device_operation6detail23launch_on_single_deviceIN2tt8tt_metal9operation23OldInfraDeviceOperationINSt3__16vectorINS4_6TensorENS7_9allocatorIS9_EEEEEEEENT_21tensor_return_value_tENS3_3stl10StrongTypeIhNS_10QueueIdTagEEERKNSE_22operation_attributes_tERKNSE_13tensor_args_tE+0x83) [0x7e76b3e079f3]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x30078ea) [0x7e76b3e078ea]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(_ZN4ttnn16device_operation6detail6invokeIN2tt8tt_metal9operation23OldInfraDeviceOperationINSt3__16vectorINS4_6TensorENS7_9allocatorIS9_EEEEEEEENT_21tensor_return_value_tENS3_3stl10StrongTypeIhNS_10QueueIdTagEEERKNSE_22operation_attributes_tERKNSE_13tensor_args_tE+0x197) [0x7e76b3e072a7]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x3006c5b) [0x7e76b3e06c5b]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x300693b) [0x7e76b3e0693b]\n --- std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> tt::tt_metal::operation::run<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>(tt::tt_metal::operation::DeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>&&, std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&, tt::stl::StrongType<unsigned char, ttnn::QueueIdTag>)\n --- ttnn::operations::reduction::ArgMaxOperation::invoke(tt::stl::StrongType<unsigned char, ttnn::QueueIdTag>, tt::tt_metal::Tensor const&, std::__1::optional<int>, std::__1::optional<CoreRangeSet> const&, bool, std::__1::optional<tt::tt_metal::MemoryConfig> const&, std::__1::optional<tt::tt_metal::Tensor>)\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156b40b) [0x7e76b236b40b]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156aeb5) [0x7e76b236aeb5]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156abdd) [0x7e76b236abdd]\n --- void tt::tt_metal::operation::launch_op_func<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>(std::__1::function<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> (std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&)> const&, std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>, std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>>, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>>)\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156a4b0) [0x7e76b236a4b0]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x1569e7f) [0x7e76b2369e7f]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x15697d4) [0x7e76b23697d4]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x155bb23) [0x7e76b235bb23]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x155b89a) [0x7e76b235b89a]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0xecbfa9) [0x7e76b1ccbfa9]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x119c33) [0x7e76ded19c33]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_MakeTpCall+0x92) [0x7e76deccb422]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce0aa) [0x7e76decce0aa]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x13c5da) [0x7e76ded3c5da]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_Call+0x5d) [0x7e76deccb1bd]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x4b88) [0x7e76dec701c8]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_FastCallDictTstate+0x6b) [0x7e76deccb57b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_Call_Prepend+0x110) [0x7e76deccb8c0]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x13c608) [0x7e76ded3c608]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_MakeTpCall+0x92) [0x7e76deccb422]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x7559) [0x7e76dec72b99]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x6857) [0x7e76dec71e97]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyEval_EvalCode+0xd2) [0x7e76dedc5962]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1be6d1) [0x7e76dedbe6d1]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a421) [0x7e76ded1a421]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x7e76dec71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe239e) [0x7e76dece239e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xd5a0d) [0x7e76decd5a0d]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x7e76dec71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce050) [0x7e76decce050]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyVectorcall_Call+0xd0) [0x7e76deccb080]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x4b88) [0x7e76dec701c8]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce050) [0x7e76decce050]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x6857) [0x7e76dec71e97]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x7e76dec72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x7e76dece167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so(+0x9c11) [0x7e76dd28fc11]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so(+0xa7af) [0x7e76dd2907af]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a00e) [0x7e76ded1a00e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1dc74b) [0x7e76deddc74b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a299) [0x7e76ded1a299]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x4b88) [0x7e76dec701c8]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x7e76dec7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce050) [0x7e76decce050]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x7518) [0x7e76dec72b58]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyEval_EvalCode+0xd2) [0x7e76dedc5962]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1be6d1) [0x7e76dedbe6d1]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a421) [0x7e76ded1a421]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x7e76dec71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x7e76dec71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x7e76dedc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x22e06a) [0x7e76dee2e06a]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(Py_RunMain+0x362) [0x7e76dee2e622]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(Py_BytesMain+0x5e) [0x7e76dee2f02e]\n --- /lib/x86_64-linux-gnu/libc.so.6(+0x2a1ca) [0x7e76de82a1ca]\n"
     ]
    }
   ],
   "source": [
    "from scripts.generate_ttnn import generate_text_simple_ttnn\n",
    "\n",
    "torch.manual_seed(123)\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "inputs_ttnn = ttnn.from_torch(\n",
    "  text_to_token_ids(start_context, tokenizer),\n",
    "  layout=ttnn.TILE_LAYOUT,\n",
    "  dtype=ttnn.uint32,\n",
    "  device=device\n",
    ")\n",
    "token_ids = generate_text_simple_ttnn(\n",
    "  model=model_ttnn,\n",
    "  idx_ttnn=inputs_ttnn,\n",
    "  max_new_tokens=50,\n",
    "  context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "  device=device\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttnn.close_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25024a55",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "TT_THROW @ /work/tt_metal/common/shape_base.cpp:29: tt::exception\ninfo:\nShapeBase[] index out of range. 2 not in [-4, 2)\nbacktrace:\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x1a2668b) [0x724f1282668b]\n --- tt::tt_metal::ShapeBase::operator[](int)\n --- ttnn::operations::reduction::ArgMax::compute_output_specs(std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&) const\n --- ttnn::operations::reduction::ArgMax::create_output_tensors(std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&) const\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x22b7cf9) [0x724f130b7cf9]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(_ZN4ttnn16device_operation6detail23launch_on_single_deviceIN2tt8tt_metal9operation23OldInfraDeviceOperationINSt3__16vectorINS4_6TensorENS7_9allocatorIS9_EEEEEEEENT_21tensor_return_value_tENS3_3stl10StrongTypeIhNS_10QueueIdTagEEERKNSE_22operation_attributes_tERKNSE_13tensor_args_tE+0x3a) [0x724f13e079aa]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x30078ea) [0x724f13e078ea]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(_ZN4ttnn16device_operation6detail6invokeIN2tt8tt_metal9operation23OldInfraDeviceOperationINSt3__16vectorINS4_6TensorENS7_9allocatorIS9_EEEEEEEENT_21tensor_return_value_tENS3_3stl10StrongTypeIhNS_10QueueIdTagEEERKNSE_22operation_attributes_tERKNSE_13tensor_args_tE+0x197) [0x724f13e072a7]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x3006c5b) [0x724f13e06c5b]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x300693b) [0x724f13e0693b]\n --- std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> tt::tt_metal::operation::run<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>(tt::tt_metal::operation::DeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>&&, std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&, tt::stl::StrongType<unsigned char, ttnn::QueueIdTag>)\n --- ttnn::operations::reduction::ArgMaxOperation::invoke(tt::stl::StrongType<unsigned char, ttnn::QueueIdTag>, tt::tt_metal::Tensor const&, std::__1::optional<int>, std::__1::optional<CoreRangeSet> const&, bool, std::__1::optional<tt::tt_metal::MemoryConfig> const&, std::__1::optional<tt::tt_metal::Tensor>)\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156b40b) [0x724f1236b40b]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156aeb5) [0x724f1236aeb5]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156abdd) [0x724f1236abdd]\n --- void tt::tt_metal::operation::launch_op_func<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>(std::__1::function<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> (std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&)> const&, std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>, std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>>, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>>)\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156a4b0) [0x724f1236a4b0]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x1569e7f) [0x724f12369e7f]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x15697d4) [0x724f123697d4]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x155bb23) [0x724f1235bb23]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x155b89a) [0x724f1235b89a]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0xecbfa9) [0x724f11ccbfa9]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x119c33) [0x724f39d19c33]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_MakeTpCall+0x92) [0x724f39ccb422]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce08a) [0x724f39cce08a]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyVectorcall_Call+0xd0) [0x724f39ccb080]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x13c5da) [0x724f39d3c5da]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_Call+0x5d) [0x724f39ccb1bd]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x4b88) [0x724f39c701c8]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_FastCallDictTstate+0x116) [0x724f39ccb626]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_Call_Prepend+0x110) [0x724f39ccb8c0]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x13c608) [0x724f39d3c608]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_MakeTpCall+0x92) [0x724f39ccb422]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x7c29) [0x724f39c73269]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyEval_EvalCode+0xd2) [0x724f39dc5962]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1be6d1) [0x724f39dbe6d1]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a421) [0x724f39d1a421]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x724f39c71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe239e) [0x724f39ce239e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xd5a0d) [0x724f39cd5a0d]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x724f39c71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce050) [0x724f39cce050]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyVectorcall_Call+0xd0) [0x724f39ccb080]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x4b88) [0x724f39c701c8]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce050) [0x724f39cce050]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x6857) [0x724f39c71e97]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so(+0x9c11) [0x724f38288c11]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so(+0xa7af) [0x724f382897af]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a00e) [0x724f39d1a00e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1dc74b) [0x724f39ddc74b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a299) [0x724f39d1a299]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x4b88) [0x724f39c701c8]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce050) [0x724f39cce050]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x7518) [0x724f39c72b58]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyEval_EvalCode+0xd2) [0x724f39dc5962]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1be6d1) [0x724f39dbe6d1]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a421) [0x724f39d1a421]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x724f39c71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x724f39c71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x22e06a) [0x724f39e2e06a]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(Py_RunMain+0x362) [0x724f39e2e622]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(Py_BytesMain+0x5e) [0x724f39e2f02e]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mttnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m  \u001b[49m\u001b[43mttnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mttnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mttnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mROW_MAJOR_LAYOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/decorators.py:333\u001b[0m, in \u001b[0;36mFastOperation.__call__\u001b[0;34m(self, *function_args, **function_kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mfunction_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunction_kwargs):\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunction_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunction_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: TT_THROW @ /work/tt_metal/common/shape_base.cpp:29: tt::exception\ninfo:\nShapeBase[] index out of range. 2 not in [-4, 2)\nbacktrace:\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x1a2668b) [0x724f1282668b]\n --- tt::tt_metal::ShapeBase::operator[](int)\n --- ttnn::operations::reduction::ArgMax::compute_output_specs(std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&) const\n --- ttnn::operations::reduction::ArgMax::create_output_tensors(std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&) const\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x22b7cf9) [0x724f130b7cf9]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(_ZN4ttnn16device_operation6detail23launch_on_single_deviceIN2tt8tt_metal9operation23OldInfraDeviceOperationINSt3__16vectorINS4_6TensorENS7_9allocatorIS9_EEEEEEEENT_21tensor_return_value_tENS3_3stl10StrongTypeIhNS_10QueueIdTagEEERKNSE_22operation_attributes_tERKNSE_13tensor_args_tE+0x3a) [0x724f13e079aa]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x30078ea) [0x724f13e078ea]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(_ZN4ttnn16device_operation6detail6invokeIN2tt8tt_metal9operation23OldInfraDeviceOperationINSt3__16vectorINS4_6TensorENS7_9allocatorIS9_EEEEEEEENT_21tensor_return_value_tENS3_3stl10StrongTypeIhNS_10QueueIdTagEEERKNSE_22operation_attributes_tERKNSE_13tensor_args_tE+0x197) [0x724f13e072a7]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x3006c5b) [0x724f13e06c5b]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x300693b) [0x724f13e0693b]\n --- std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> tt::tt_metal::operation::run<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>(tt::tt_metal::operation::DeviceOperation<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>&&, std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&, tt::stl::StrongType<unsigned char, ttnn::QueueIdTag>)\n --- ttnn::operations::reduction::ArgMaxOperation::invoke(tt::stl::StrongType<unsigned char, ttnn::QueueIdTag>, tt::tt_metal::Tensor const&, std::__1::optional<int>, std::__1::optional<CoreRangeSet> const&, bool, std::__1::optional<tt::tt_metal::MemoryConfig> const&, std::__1::optional<tt::tt_metal::Tensor>)\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156b40b) [0x724f1236b40b]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156aeb5) [0x724f1236aeb5]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156abdd) [0x724f1236abdd]\n --- void tt::tt_metal::operation::launch_op_func<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>>(std::__1::function<std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> (std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>> const&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>> const&)> const&, std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>, std::__1::vector<tt::tt_metal::Tensor, std::__1::allocator<tt::tt_metal::Tensor>>&, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor const>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor const>>>, std::__1::vector<std::__1::optional<tt::tt_metal::Tensor>, std::__1::allocator<std::__1::optional<tt::tt_metal::Tensor>>>)\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x156a4b0) [0x724f1236a4b0]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x1569e7f) [0x724f12369e7f]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x15697d4) [0x724f123697d4]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x155bb23) [0x724f1235bb23]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0x155b89a) [0x724f1235b89a]\n --- /home/avgdev/code/ttnn-sandbox/.venv/lib/python3.10/site-packages/ttnn/_ttnn.cpython-310-x86_64-linux-gnu.so(+0xecbfa9) [0x724f11ccbfa9]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x119c33) [0x724f39d19c33]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_MakeTpCall+0x92) [0x724f39ccb422]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce08a) [0x724f39cce08a]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyVectorcall_Call+0xd0) [0x724f39ccb080]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x13c5da) [0x724f39d3c5da]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_Call+0x5d) [0x724f39ccb1bd]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x4b88) [0x724f39c701c8]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_FastCallDictTstate+0x116) [0x724f39ccb626]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_Call_Prepend+0x110) [0x724f39ccb8c0]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x13c608) [0x724f39d3c608]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyObject_MakeTpCall+0x92) [0x724f39ccb422]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x7c29) [0x724f39c73269]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyEval_EvalCode+0xd2) [0x724f39dc5962]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1be6d1) [0x724f39dbe6d1]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a421) [0x724f39d1a421]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x724f39c71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe239e) [0x724f39ce239e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xd5a0d) [0x724f39cd5a0d]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x724f39c71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce050) [0x724f39cce050]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyVectorcall_Call+0xd0) [0x724f39ccb080]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x4b88) [0x724f39c701c8]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce050) [0x724f39cce050]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x6857) [0x724f39c71e97]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x775b) [0x724f39c72d9b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xe167e) [0x724f39ce167e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so(+0x9c11) [0x724f38288c11]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/python3.10/lib-dynload/_asyncio.cpython-310-x86_64-linux-gnu.so(+0xa7af) [0x724f382897af]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a00e) [0x724f39d1a00e]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1dc74b) [0x724f39ddc74b]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a299) [0x724f39d1a299]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x4b88) [0x724f39c701c8]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x710f) [0x724f39c7274f]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0xce050) [0x724f39cce050]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x7518) [0x724f39c72b58]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(PyEval_EvalCode+0xd2) [0x724f39dc5962]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1be6d1) [0x724f39dbe6d1]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x11a421) [0x724f39d1a421]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x724f39c71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x66c6) [0x724f39c71d06]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x1c5b34) [0x724f39dc5b34]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(+0x22e06a) [0x724f39e2e06a]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(Py_RunMain+0x362) [0x724f39e2e622]\n --- /home/avgdev/.pyenv/versions/3.10.11/lib/libpython3.10.so.1.0(Py_BytesMain+0x5e) [0x724f39e2f02e]\n"
     ]
    }
   ],
   "source": [
    "ttnn.argmax(\n",
    "  ttnn.from_torch(\n",
    "    torch.tensor([[1, 3, 2]]), \n",
    "    dtype=ttnn.bfloat16,\n",
    "    layout=ttnn.ROW_MAJOR_LAYOUT,\n",
    "    device=device\n",
    "  ),\n",
    "  dim=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea75ed1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
