{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5eda073",
   "metadata": {},
   "source": [
    "# Pretraining GPT2\n",
    "\n",
    "It has now come time to do one of the most exciting parts in our learning journey. We are going to train a GPT2 model in this notebook! We are not going to use a GPU, but instead a CPU. I will be using the same system I have been using with other notebooks.\n",
    "\n",
    "- CPU: Core i7 13700\n",
    "- Accelerator: Tenstorrent Wormhole n150d\n",
    "\n",
    "Given the amount of data we have to train the model, we should have more than enough compute capability to train.\n",
    "\n",
    "To start off, we'll juse the same `GPT_CONFIG_124M` as before when building our model. This time we will shortent he context length from **1024** to **256** since our data set doesn't have enough tokens for the original context length. It will also make training go faster too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931d1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.0,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0647de",
   "metadata": {},
   "source": [
    "## Torch Implementation\n",
    "\n",
    "This time, the `torch` implementation isn't just for show, but now it is going to required to do since we are now going to need the implementation for training. \n",
    "\n",
    "An important update here is that our `GPTModel` now lives in our `scripts` folder. I didn't really change much there, but take the opportunity now to review it if you can. \n",
    "\n",
    "Additionally, like what Sebastian always does, let's set the seed for `torch` to create reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b72c4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ed6c89230b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from scripts.gpt2_model import GPTModel\n",
    "\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda4e337",
   "metadata": {},
   "source": [
    "We will just instantiate the model. Since our config already has 0 drop out, we don't necessarily need to set `eval` mode for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345b27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da393ec9",
   "metadata": {},
   "source": [
    "Define some helpers. Note that these functions will also live in `scripts.utils`, so we can import those in the future.\n",
    "\n",
    "* `text_to_token_ids` - This will _encode_ text to a tensor of integers representing the token IDs.\n",
    "* `token_ids_to_text` - This will _decode_ the tensor of integers as token IDs into text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35f9b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639330fd",
   "metadata": {},
   "source": [
    "Let's test the model with what we have at this moment. Since we have not trained our model yet, we expect it to generate some garbage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70abd679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "from scripts.generate import generate_text_simple\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "  model=model,\n",
    "  idx=text_to_token_ids(start_context, tokenizer),\n",
    "  max_new_tokens=10,\n",
    "  context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae6ae2",
   "metadata": {},
   "source": [
    "## Loss Calculation\n",
    "\n",
    "The following example shows 2 input batches of text \"Every effort moves\" and \"I really like\". Their corresponding target batches are \"effort moves you\" and \"really like chocolate\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e4aa20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[16833,  3626,  6100],\n",
       "         [   40,  1107,   588]]),\n",
       " tensor([[ 3626,  6100,   345],\n",
       "         [ 1107,   588, 11311]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([\n",
    "    [16833, 3626, 6100], # Every effort moves\n",
    "    [40,    1107, 588] # I really like\n",
    "])\n",
    "\n",
    "targets = torch.tensor([\n",
    "    [3626, 6100, 345  ],  # effort moves you\n",
    "    [1107,  588, 11311] # really like chocolate\n",
    "])\n",
    "\n",
    "inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade69d71",
   "metadata": {},
   "source": [
    "`logits` is the resulting tensor of performing a \"forward pass\" through the model. Basically, logits is what the model produces in inference. \n",
    "\n",
    "The logits need to be turned into values that represent probability, where if we add all the values across the last dimension, we will get the result that is pretty close to `1.000`.\n",
    "\n",
    "To do that, we can perform a `softmax` on this tensor to create a `probas` tensor. This has a shape of: `batch size, number of tokens in input, vocab size`.\n",
    "\n",
    "In this case we expect the following size: (2, 3, 50257).\n",
    "\n",
    "Notice the last dimension indicates all probabilities of tokens which can occur in context, to succeed the current token being observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346c2157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.8849e-05, 1.5172e-05, 1.1687e-05,  ..., 2.2409e-05,\n",
       "           6.9776e-06, 1.8776e-05],\n",
       "          [9.1569e-06, 1.0062e-05, 7.8786e-06,  ..., 2.9090e-05,\n",
       "           6.0103e-06, 1.3571e-05],\n",
       "          [2.9877e-05, 8.8507e-06, 1.5741e-05,  ..., 3.5456e-05,\n",
       "           1.4094e-05, 1.3526e-05]],\n",
       " \n",
       "         [[1.2561e-05, 2.0538e-05, 1.4332e-05,  ..., 1.0389e-05,\n",
       "           3.4784e-05, 1.4239e-05],\n",
       "          [7.2731e-06, 1.7864e-05, 1.0565e-05,  ..., 2.1206e-05,\n",
       "           1.1390e-05, 1.5559e-05],\n",
       "          [2.9496e-05, 3.3605e-05, 4.1029e-05,  ..., 6.5249e-06,\n",
       "           5.8203e-05, 1.3698e-05]]], grad_fn=<SoftmaxBackward0>),\n",
       " torch.Size([2, 3, 50257]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "\n",
    "probas, probas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f8d56",
   "metadata": {},
   "source": [
    "For each word, we find an individual token to succeed the text. This is as easy as finding the _index_ of the highest value in the `probas` tensor for that specific token. Let's use `torch.argmax` to do that across the last dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82a4a0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[16657],\n",
       "         [  339],\n",
       "         [42826]],\n",
       "\n",
       "        [[49906],\n",
       "         [29669],\n",
       "         [41751]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a4869",
   "metadata": {},
   "source": [
    "But too bad! we're nowhere close to our target! Here is a comparison of what our produced compared to what we should have received as the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4708dad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n",
      "Targets batch 2:  really like chocolate\n",
      "Outputs batch 2:  pressuring empoweredfaith\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "\n",
    "print(f\"Targets batch 2: {token_ids_to_text(targets[1], tokenizer)}\")\n",
    "print(f\"Outputs batch 2: {token_ids_to_text(token_ids[1].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a0dfa2",
   "metadata": {},
   "source": [
    "I chuckle that my employer's name was generated as likely token to be generated.\n",
    "\n",
    "So what did this probabilities look like for the _real_ indices for targets? You'll find them to be small. The goal now is to increase these probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8df0a351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05], grad_fn=<IndexBackward0>)\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289da65",
   "metadata": {},
   "source": [
    "Take the log for individual probabilities and then concatenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bc3cc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561],\n",
       "       grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "log_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833da750",
   "metadata": {},
   "source": [
    "Take the average and negate to make it positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f9b545f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-10.7940, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "avg_log_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7518b024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7940, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "neg_avg_log_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b2d99",
   "metadata": {},
   "source": [
    "You will notice that the loss is very large. The above is basically what we call \"cross entropy loss\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a6310",
   "metadata": {},
   "source": [
    "## Cross Entropy\n",
    "\n",
    "We can generalize these calculations. We use `torch.cross_entropy` to do everything we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c07811e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5abec1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea174aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2ca81b",
   "metadata": {},
   "source": [
    "We can calculate the perplexity too -- from what the book Build a Large Language Model says, it represents the degree of tokens that the model isn't very sure about.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "480caa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203, grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99233a6",
   "metadata": {},
   "source": [
    "## Data Preparation for Training\n",
    "\n",
    "We are getting closer to training. Let's prepare the data set for training. We had downloaded `the-verdict.txt` a while back, and now it is time to use it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fa747d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 characters: I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n",
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/the-verdict.txt\", \"r\") as f:\n",
    "  text_data = f.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"First 100 characters:\", text_data[:100])\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a398b737",
   "metadata": {},
   "source": [
    "Now let's split the data into training and validation sets. We'll use 90% of the data for our training data, and the rest of the 10% as the validation data set.\n",
    "\n",
    "To create these data loaders, let's tap into our `create_dataloader_v1` function we wrote a few notebooks back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ce841e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.prepare_data import create_dataloader_v1\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392a561",
   "metadata": {},
   "source": [
    "Our data set is really small, so we shouldn't have too many batches. Turns out, with `the-verdict.txt`, we only have 1 validation batch for our context length of 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74a59bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e37f09",
   "metadata": {},
   "source": [
    "Let's verify how many tokens are in the training and validation batches individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbca7766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bdc302",
   "metadata": {},
   "source": [
    "## Training Loss Calculation\n",
    "\n",
    "The main meat of the training loop involves performing calculations on the loss. We will calculate the cross-entropy loss between an input batch and target batch. \n",
    "\n",
    "What is returned is a tensor representing for given token, we give indication of the loss for each other token within the given vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f211f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model):\n",
    "    input_batch, target_batch = input_batch, target_batch\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0e4da",
   "metadata": {},
   "source": [
    "`calc_loss_loader` will wrap around the `calc_loss_batch` and process for every input batch and its corresponding target batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd4f1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_loss_loader(data_loader, model, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da140f10",
   "metadata": {},
   "source": [
    "What's the current training loss and validation loss for our model? Well, since we haven't trained it yet, I wouldn't be surprised if it is really high!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7ae4e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "train_loss = calc_loss_loader(train_loader, model)\n",
    "val_loss = calc_loss_loader(val_loader, model)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc886e",
   "metadata": {},
   "source": [
    "## Training Our Model\n",
    "\n",
    "The time has come to train our model! Here, we will use pure CPU training and inferencing, and I've simplified the original code a bit to make things easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c31d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses = [], []\n",
    "    global_step = -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, start_context)\n",
    "\n",
    "    return train_losses, val_losses \n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, eval_iter):\n",
    "    train_loss = calc_loss_loader(train_loader, model, num_batches=eval_iter)\n",
    "    val_loss = calc_loss_loader(val_loader, model, num_batches=eval_iter)\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, start_context):\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer)\n",
    "    token_ids = generate_text_simple(\n",
    "        model=model, idx=encoded,\n",
    "        max_new_tokens=50, context_size=context_size\n",
    "    )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa275dda",
   "metadata": {},
   "source": [
    "Now, let's execute the training loop. We will run this for 10 epochs. It's a good opportunity to also time the entire training. On my i7 13700, it takes a little over 2 minutes for this training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20673ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.794, Val loss 9.909\n",
      "Ep 1 (Step 000005): Train loss 8.038, Val loss 8.324\n",
      "Every effort moves you,,,,,,,,,,,,,,.                                   \n",
      "Ep 2 (Step 000010): Train loss 6.598, Val loss 7.041\n",
      "Ep 2 (Step 000015): Train loss 5.996, Val loss 6.575\n",
      "Every effort moves you, and, and, and, and, and, and, and. \", and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.558, Val loss 6.444\n",
      "Ep 3 (Step 000025): Train loss 5.956, Val loss 7.675\n",
      "Every effort moves you.                                                 \n",
      "Ep 4 (Step 000030): Train loss 4.243, Val loss 6.283\n",
      "Ep 4 (Step 000035): Train loss 4.304, Val loss 6.210\n",
      "Every effort moves you.               \"I--and's--and it's had been, and I had been the, and I had been the honour of the, and he had been, I had\n",
      "Ep 5 (Step 000040): Train loss 3.443, Val loss 6.196\n",
      "Every effort moves you know it was not a littleI glanced after him, and I had been his eyes: \"--his, in fact--as of the picture.     \"--and it's his pictures, and down, and he had been\n",
      "Ep 6 (Step 000045): Train loss 3.226, Val loss 6.247\n",
      "Ep 6 (Step 000050): Train loss 2.691, Val loss 6.236\n",
      "Every effort moves you know; and in a little Mrs.  \"--I looked. \"I looked--and me.  \"Oh, in the moment--as Jack himself, and he had it, a, and down, and he was his\n",
      "Ep 7 (Step 000055): Train loss 2.538, Val loss 6.263\n",
      "Ep 7 (Step 000060): Train loss 1.742, Val loss 6.182\n",
      "Every effort moves you know.\" \"Yes--I glanced after him, and Mrs.  \"I looked--I looked up, I felt to see a smile behind his pictures--as I had been his painting, the donkey. \"There were days when I\n",
      "Ep 8 (Step 000065): Train loss 1.326, Val loss 6.250\n",
      "Ep 8 (Step 000070): Train loss 1.070, Val loss 6.333\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 0.775, Val loss 6.334\n",
      "Ep 9 (Step 000080): Train loss 0.545, Val loss 6.370\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the honour being _mine_--oh, and in his\n",
      "Ep 10 (Step 000085): Train loss 0.370, Val loss 6.481\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Took this long to train: 135609.7445487976 ms\n"
     ]
    }
   ],
   "source": [
    "from scripts.perf_timer import PerfTimer\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "timer = PerfTimer()\n",
    "\n",
    "timer.start()\n",
    "train_losses, val_losses = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "timer.stop()\n",
    "\n",
    "print(f\"Took this long to train: {timer.elapsed_ms()} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e60346ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from scripts.generate import generate_text_simple\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf9e9a",
   "metadata": {},
   "source": [
    "## Saving the Model Weights\n",
    "\n",
    "After all our hard work, let's save the model weights so that we can reload them later to perform inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6713c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/gpt2-verdict-model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874af154",
   "metadata": {},
   "source": [
    "## Reload the Model\n",
    "\n",
    "To test to see if we were able to successfully save the model, let's take the chance to now load the model back into memory and reassign. We'll perform inference again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65e3036d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from scripts.gpt2_model import GPTModel\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(\n",
    "  torch.load(\"models/gpt2-verdict-model.pth\", weights_only=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f10ff8",
   "metadata": {},
   "source": [
    "Perform inference. Let's generate 50 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff565267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated tokens in 1024.2621898651123 ms\n",
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "from scripts.perf_timer import PerfTimer\n",
    "\n",
    "perf_timer = PerfTimer()\n",
    "\n",
    "perf_timer.start()\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "perf_timer.stop()\n",
    "\n",
    "print(\"Generated tokens in\", perf_timer.elapsed_ms(), \"ms\")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8951d6a",
   "metadata": {},
   "source": [
    "## TTNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92299a29",
   "metadata": {},
   "source": [
    "We are not going to train the model using TTNN, instead, we will use it to perform inference in an already trained model. In this case, we diligently trained the GP2 model with our data set using CPU and had saved it to disk. We can reload those weights and reapply them to the GPTModel_ttnn class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f4a5ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 16:39:09.930 | DEBUG    | ttnn.library_tweaks:prepare_dir_as_metal_home:54 - Existing installation of 0.57.0rc60+any detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 16:39:10.033 | DEBUG    | ttnn:<module>:83 - Initial ttnn.CONFIG:\n",
      "Config{cache_path=/home/avgdev/.cache/ttnn,model_cache_path=/home/avgdev/.cache/ttnn/models,tmp_dir=/tmp/ttnn,enable_model_cache=false,enable_fast_runtime_mode=true,throw_exception_on_fallback=false,enable_logging=false,enable_graph_report=false,enable_detailed_buffer_report=false,enable_detailed_tensor_report=false,enable_comparison_mode=false,comparison_mode_should_raise_exception=false,comparison_mode_pcc=0.9999,root_report_path=generated/ttnn/reports,report_name=std::nullopt,std::nullopt}\n",
      "New chip! We now have 1 chips\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Device | INFO     | Opening user mode device driver\n",
      "\u001b[32m2025-05-13 16:39:10.109\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\n",
      "\u001b[32m2025-05-13 16:39:10.120\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-05-13 16:39:10.122\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Harvesting mask for chip 0 is 0x200 (physical layout: 0x1, logical: 0x200, simulated harvesting mask: 0x0).\n",
      "\u001b[32m2025-05-13 16:39:10.123\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-05-13 16:39:10.123\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected PCI devices: [0]\n",
      "\u001b[32m2025-05-13 16:39:10.123\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using local chip ids: {0} and remote chip ids {}\n",
      "\u001b[32m2025-05-13 16:39:10.196\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Software version 6.0.0, Ethernet FW version 6.14.0 (Device 0)\n",
      "                  Metal | INFO     | Initializing device 0. Program cache is NOT enabled\n",
      "                  Metal | INFO     | AI CLK for device 0 is:   1000 MHz\n",
      "                  Metal | INFO     | Enabling program cache on device 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chip initialization complete (found )\n",
      "Chip initializing complete...\n",
      " ARC\n",
      "\n",
      " [4/4] DRAM\n",
      "\n",
      " [16/16] ETH\n",
      "\n",
      " CPU\n",
      "\n",
      "Chip detection complete (found )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ttnn\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch import nn\n",
    "from scripts.text_helpers import text_to_token_ids, token_ids_to_text\n",
    "from scripts.gpt2_model import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.0,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "device = None\n",
    "\n",
    "if device:\n",
    "  ttnn.close_device(device)\n",
    "\n",
    "device_id = 0\n",
    "device = ttnn.open_device(device_id=device_id)\n",
    "\n",
    "device.enable_program_cache()\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(\n",
    "  torch.load(\"models/gpt2-verdict-model.pth\", weights_only=True)\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d55b4",
   "metadata": {},
   "source": [
    "## Open the Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "633217a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Metal | INFO     | Closing device 0\n",
      "                  Metal | INFO     | Disabling and clearing program cache on device 0\n",
      "                  Metal | INFO     | Initializing device 0. Program cache is NOT enabled\n",
      "                  Metal | INFO     | AI CLK for device 0 is:   1000 MHz\n",
      "                  Metal | INFO     | Enabling program cache on device 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if device:\n",
    "  ttnn.close_device(device)\n",
    "\n",
    "from scripts.gpt2_model import GPTModel\n",
    "\n",
    "device_id = 0\n",
    "device = ttnn.open_device(device_id=device_id)\n",
    "\n",
    "device.enable_program_cache()\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(\n",
    "  torch.load(\"models/gpt2-verdict-model.pth\", weights_only=True)\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ebc5ab",
   "metadata": {},
   "source": [
    "## Initialize the GPT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db15bd6",
   "metadata": {},
   "source": [
    "We will reload the model to make sure that we have the latest changes from disk. \n",
    "\n",
    "Since we already have a model instance, we'll just need to copy over all the weights to the `ttnn` version of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c1f1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.gpt2_model_ttnn import GPTModel_ttnn, TransformerBlock_ttnn\n",
    "\n",
    "model_ttnn = GPTModel_ttnn(GPT_CONFIG_124M, device)\n",
    "\n",
    "model_ttnn.pos_emb.weight = torch.nn.Parameter(model.pos_emb.weight) \n",
    "model_ttnn.tok_emb.weight = torch.nn.Parameter(model.tok_emb.weight)\n",
    "\n",
    "for i, block in enumerate(model.trf_blocks):\n",
    "  t = model_ttnn.trf_blocks_ttnn[i]\n",
    "\n",
    "  t.att.W_key.weight = torch.nn.Parameter(block.att.W_key.weight)\n",
    "  t.att.W_key.bias = torch.nn.Parameter(block.att.W_key.bias)\n",
    "\n",
    "  t.att.W_query.weight = torch.nn.Parameter(block.att.W_query.weight)\n",
    "  t.att.W_query.bias = torch.nn.Parameter(block.att.W_query.bias)\n",
    "  \n",
    "  t.att.W_value.weight = torch.nn.Parameter(block.att.W_value.weight)\n",
    "  t.att.W_value.bias = torch.nn.Parameter(block.att.W_value.bias)\n",
    "  \n",
    "  t.att.out_proj.weight = torch.nn.Parameter(block.att.out_proj.weight)\n",
    "  t.att.out_proj.bias = torch.nn.Parameter(block.att.out_proj.bias)\n",
    "\n",
    "  t.ff.lin_1.weight = torch.nn.Parameter(block.ff.layer[0].weight)\n",
    "  t.ff.lin_1.bias = torch.nn.Parameter(block.ff.layer[0].bias)\n",
    "  t.ff.lin_2.weight = torch.nn.Parameter(block.ff.layer[2].weight)\n",
    "  t.ff.lin_2.bias = torch.nn.Parameter(block.ff.layer[2].bias)\n",
    "\n",
    "  t.norm1.scale = torch.nn.Parameter(block.norm1.scale)\n",
    "  t.norm1.shift = torch.nn.Parameter(block.norm1.shift)\n",
    "\n",
    "  t.norm2.scale = torch.nn.Parameter(block.norm2.scale)\n",
    "  t.norm2.shift = torch.nn.Parameter(block.norm2.shift)\n",
    "\n",
    "model_ttnn.final_norm.shift = torch.nn.Parameter(model.final_norm.shift)\n",
    "model_ttnn.final_norm.scale = torch.nn.Parameter(model.final_norm.scale)\n",
    "model_ttnn.out_head.weight = torch.nn.Parameter(model.out_head.weight)\n",
    "\n",
    "model_ttnn.update_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b274e049",
   "metadata": {},
   "source": [
    "## Out Head, Final Norm, and Transformer Blocks Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "680dcf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "Shape([50257, 768])\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "Overall Status: âœ… PASS\n",
      "\n",
      "\n",
      "Overall Status: âœ… PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_diff': 0.0,\n",
       " 'mean_diff': 0.0,\n",
       " 'correlation': 1.0078125,\n",
       " 'max_diff_status': True,\n",
       " 'mean_diff_status': True,\n",
       " 'correlation_status': True,\n",
       " 'overall_status': True}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.compare_tensors import compare_tensors\n",
    "\n",
    "# position and token embedding comparisons\n",
    "compare_tensors(\n",
    "  ttnn.to_torch(\n",
    "    ttnn.reshape(\n",
    "      (model_ttnn.tok_emb_ttnn),\n",
    "      (1, model_ttnn.tok_emb_ttnn.shape[0], model_ttnn.tok_emb_ttnn.shape[1])\n",
    "    )\n",
    "  ),\n",
    "  model.tok_emb.weight.unsqueeze(0),\n",
    "  suppress_details=True\n",
    ")\n",
    "\n",
    "compare_tensors(\n",
    "  ttnn.to_torch(\n",
    "    ttnn.reshape(\n",
    "      (model_ttnn.pos_emb_ttnn),\n",
    "      (1, model_ttnn.pos_emb_ttnn.shape[0], model_ttnn.pos_emb_ttnn.shape[1])\n",
    "    )\n",
    "  ),\n",
    "  model.pos_emb.weight.unsqueeze(0),\n",
    "  suppress_details=True\n",
    ")\n",
    "# outhead comparison\n",
    "out_head_shape = model_ttnn.out_head_ttnn.shape\n",
    "print(out_head_shape)\n",
    "\n",
    "compare_tensors(\n",
    "  ttnn.to_torch(\n",
    "    ttnn.reshape(\n",
    "      model_ttnn.out_head_ttnn,\n",
    "      (1, out_head_shape[0], out_head_shape[1])\n",
    "    )\n",
    "  ),\n",
    "  model.out_head.weight.unsqueeze(0),\n",
    "  suppress_details=True\n",
    ")\n",
    "\n",
    "for i, block in enumerate(model.trf_blocks):\n",
    "  t = model_ttnn.trf_blocks_ttnn[i]\n",
    "\n",
    "  compare_tensors(\n",
    "    ttnn.to_torch(\n",
    "      ttnn.reshape(\n",
    "        t.att.W_key_ttnn,\n",
    "        (1, t.att.W_key_ttnn.shape[0], t.att.W_key_ttnn.shape[1]))\n",
    "    ),\n",
    "    model.trf_blocks[i].att.W_key.weight.unsqueeze(0),\n",
    "    suppress_details=True\n",
    "  )\n",
    "  compare_tensors(\n",
    "    ttnn.to_torch(\n",
    "      ttnn.reshape(\n",
    "        t.att.W_query_ttnn,\n",
    "        (1, t.att.W_query_ttnn.shape[0], t.att.W_query_ttnn.shape[1]))\n",
    "    ),\n",
    "    model.trf_blocks[i].att.W_query.weight.unsqueeze(0),\n",
    "    suppress_details=True\n",
    "  )\n",
    "  compare_tensors(\n",
    "    ttnn.to_torch(\n",
    "      ttnn.reshape(\n",
    "        t.att.W_value_ttnn,\n",
    "        (1, t.att.W_value_ttnn.shape[0], t.att.W_value_ttnn.shape[1]))\n",
    "    ),\n",
    "    model.trf_blocks[i].att.W_value.weight.unsqueeze(0),\n",
    "    suppress_details=True\n",
    "  )\n",
    "  compare_tensors(\n",
    "    ttnn.to_torch(\n",
    "      ttnn.reshape(\n",
    "        t.att.out_proj_ttnn,\n",
    "        (1, t.att.out_proj_ttnn.shape[0], t.att.out_proj_ttnn.shape[1]))\n",
    "    ),\n",
    "    model.trf_blocks[i].att.out_proj.weight.unsqueeze(0),\n",
    "    suppress_details=True\n",
    "  )\n",
    "  compare_tensors(\n",
    "    ttnn.to_torch(\n",
    "      ttnn.reshape(\n",
    "        t.att.out_proj_bias_ttnn,\n",
    "        (1, 1, t.att.out_proj_bias_ttnn.shape[0]))\n",
    "    ),\n",
    "    model.trf_blocks[i].att.out_proj.bias.unsqueeze(0).unsqueeze(0),\n",
    "    suppress_details=True\n",
    "  )\n",
    "\n",
    "# Final Norm comparison\n",
    "final_norm_shift_shape = model_ttnn.final_norm.shift_ttnn.shape\n",
    "final_norm_scale_shape = model_ttnn.final_norm.scale_ttnn.shape\n",
    "\n",
    "compare_tensors(\n",
    "  ttnn.to_torch(\n",
    "    ttnn.reshape(\n",
    "      model_ttnn.final_norm.shift_ttnn,\n",
    "      (1, 1, final_norm_shift_shape[0])\n",
    "    )\n",
    "  ),\n",
    "  model.final_norm.shift.unsqueeze(0).unsqueeze(0),\n",
    "  suppress_details=True\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "compare_tensors(\n",
    "  ttnn.to_torch(\n",
    "    ttnn.reshape(\n",
    "      model_ttnn.final_norm.scale_ttnn,\n",
    "      (1, 1, final_norm_scale_shape[0])\n",
    "    )\n",
    "  ),\n",
    "  model.final_norm.scale.unsqueeze(0).unsqueeze(0),\n",
    "  suppress_details=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6b802",
   "metadata": {},
   "source": [
    "## Text Generation with Loaded Weights on Tenstorrent Hardware\n",
    "\n",
    "**! A little note about this section. !**\n",
    "\n",
    "Unfortunately as of May 2025, `ttnn` seems to have a bit of trouble calculating the `argmax` of a tensor. It also has trouble with concatenating two tensors together too. \n",
    "\n",
    "Because of that, I have to move the tensors from the device memory _into_ host memory. This sucks because then we just nullify all the work we did in \"accelerating\" the computation for inference.\n",
    "\n",
    "The transfer between the Wormhole and the Core i7 13700 is just too slow. Repeating this for multiple iterations of token generation, it just results in a horrible experience.\n",
    "\n",
    "For the sake of education, I will be assuming that we do get acceleration from all this in the world where `argmax` and `concat` are fixed in `ttnn`. \n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d827af49",
   "metadata": {},
   "source": [
    "Now, the output text we get from doing all inference on the hardware should be the same as the CPU's generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0247d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated tokens in 1264.6911144256592 ms\n",
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "from scripts.generate_ttnn import generate_text_simple_ttnn\n",
    "from scripts.perf_timer import PerfTimer\n",
    "\n",
    "torch.manual_seed(123)\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "perf_timer = PerfTimer()\n",
    "perf_timer.start()\n",
    "inputs_ttnn = ttnn.from_torch(\n",
    "  text_to_token_ids(start_context, tokenizer),\n",
    "  dtype=ttnn.uint32,\n",
    "  layout=ttnn.TILE_LAYOUT,\n",
    "  device=device\n",
    ")\n",
    "token_ids_ttnn = generate_text_simple_ttnn(\n",
    "  model=model_ttnn,\n",
    "  idx_ttnn=inputs_ttnn,\n",
    "  max_new_tokens=50,\n",
    "  context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "  device=device\n",
    ")\n",
    "\n",
    "token_ids = ttnn.to_torch(token_ids_ttnn)\n",
    "perf_timer.stop()\n",
    "\n",
    "print(\"Generated tokens in\", perf_timer.elapsed_ms(), \"ms\")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c27c38f",
   "metadata": {},
   "source": [
    "Finally, close the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46c2123b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Metal | INFO     | Closing device 0\n",
      "                  Metal | INFO     | Disabling and clearing program cache on device 0\n"
     ]
    }
   ],
   "source": [
    "ttnn.close_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2fdb5b",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "`ttnn` is an operator library. It's meant for raw compute of tensors. Therefore, we should leverage the library on Tenstorrent hardware for _inference_. \n",
    "\n",
    "There are ways we can train on the hardware, but I'm not skilled enough yet.\n",
    "\n",
    "For the rest of the notebook series, we'll continue to use the method in training through CPU, and inferencing through Tenstorrent hardware. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
