{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b10c854-bfd6-4404-b09b-f310451cf2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: tiktoken in /home/avgdev/code/tt-sandbox/.venv/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/avgdev/code/tt-sandbox/.venv/lib/python3.10/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/avgdev/code/tt-sandbox/.venv/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/avgdev/code/tt-sandbox/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/avgdev/code/tt-sandbox/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/avgdev/code/tt-sandbox/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/avgdev/code/tt-sandbox/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058587b2-27d6-4c0c-a3dc-642c1d209d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b85a6f1-3925-46a7-95e5-014a51a45975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 703, 389, 345, 30, 220, 50256, 632, 338, 257, 27737, 1110, 13]\n",
      "Hello, how are you? <|endoftext|> It's a sunny day.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"Hello, how are you? <|endoftext|> It's a sunny day.\"\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)\n",
    "\n",
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d043c7a8-5b7a-4791-bd50-cdf67ce6befe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap g\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.exists(\"data/the-verdict.txt\"):\n",
    "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "           \"the-verdict.txt\")\n",
    "    file_path = \"data/the-verdict.txt\"\n",
    "    urllib.request.urlretrieve(url, file_path)\n",
    "    \n",
    "with open(\"data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(raw_text[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2088da34-095d-4822-bd0c-6a14ef1a82e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 14:29:54.135 | DEBUG    | ttnn:<module>:83 - Initial ttnn.CONFIG:\n",
      "Config{cache_path=/home/avgdev/.cache/ttnn,model_cache_path=/home/avgdev/.cache/ttnn/models,tmp_dir=/tmp/ttnn,enable_model_cache=false,enable_fast_runtime_mode=true,throw_exception_on_fallback=false,enable_logging=false,enable_graph_report=false,enable_detailed_buffer_report=false,enable_detailed_tensor_report=false,enable_comparison_mode=false,comparison_mode_should_raise_exception=false,comparison_mode_pcc=0.9999,root_report_path=generated/ttnn/reports,report_name=std::nullopt,std::nullopt}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcaa46e7-8799-4cc0-96c6-15d029210b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ttnn.Tensor([[   40,   367,  ...,  2885,  1464]], shape=Shape([1, 4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR), ttnn.Tensor([[  367,  2885,  ...,  1464,  1807]], shape=Shape([1, 4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR)]\n"
     ]
    }
   ],
   "source": [
    "from scripts.prepare_data import create_dataloader_v1\n",
    "\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "\n",
    "batches = [ttnn.from_torch(batch, dtype=ttnn.uint32) for batch in first_batch]\n",
    "\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff68b440-6771-49ff-bedf-18593263eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ttnn_batch(torch_batch, device=None):\n",
    "    return ttnn.from_torch(torch_batch, dtype=ttnn.uint32, device=device, layout=ttnn.ROW_MAJOR_LAYOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd6001b-b1c1-4564-9d99-16b0de5f92fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ttnn.Tensor([[  367,  2885,  ...,  1464,  1807]], shape=Shape([1, 4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR), ttnn.Tensor([[ 2885,  1464,  ...,  1807,  3619]], shape=Shape([1, 4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR)]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print([to_ttnn_batch(batch) for batch in second_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3109a8f6-0966-44b2-822b-ce0eab8fcbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " ttnn.Tensor([[   40,   367,  ...,  2885,  1464],\n",
      "             [ 1807,  3619,  ...,   402,   271],\n",
      "             ...,\n",
      "             [ 1049,  5975,  ...,   284,   502],\n",
      "             [  284,  3285,  ...,   326,    11]], shape=Shape([8, 4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR)\n",
      "\n",
      "Targets:\n",
      " ttnn.Tensor([[  367,  2885,  ...,  1464,  1807],\n",
      "             [ 3619,   402,  ...,   271, 10899],\n",
      "             ...,\n",
      "             [ 5975,   284,  ...,   502,   284],\n",
      "             [ 3285,   326,  ...,    11,   287]], shape=Shape([8, 4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR)\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", to_ttnn_batch(inputs))\n",
    "print(\"\\nTargets:\\n\", to_ttnn_batch(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0957e76-57ba-41aa-9324-cbb10c21a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "torch.manual_seed(123)\n",
    "\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "\n",
    "# we need to recreate this with ttnn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91bddd1b-712d-45b5-90ef-3f19b0bf9770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Device | INFO     | Opening user mode device driver\n",
      "\u001b[32m2025-04-19 14:29:55.369\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\n",
      "\u001b[32m2025-04-19 14:29:55.382\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-04-19 14:29:55.383\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Harvesting mask for chip 0 is 0x200 (physical layout: 0x1, logical: 0x200, simulated harvesting mask: 0x0).\n",
      "\u001b[32m2025-04-19 14:29:55.384\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-04-19 14:29:55.385\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected PCI devices: [0]\n",
      "\u001b[32m2025-04-19 14:29:55.385\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using local chip ids: {0} and remote chip ids {}\n",
      "\u001b[32m2025-04-19 14:29:55.412\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Software version 6.0.0, Ethernet FW version 6.14.0 (Device 0)\n",
      "                  Metal | INFO     | Initializing device 0. Program cache is NOT enabled\n",
      "                  Metal | INFO     | AI CLK for device 0 is:   1000 MHz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New chip! We now have 1 chips\n",
      "Chip initialization complete (found )\n",
      "Chip initializing complete...\n",
      " ARC\n",
      "\n",
      " [4/4] DRAM\n",
      "\n",
      " [16/16] ETH\n",
      "\n",
      " CPU\n",
      "\n",
      "Chip detection complete (found )\n"
     ]
    }
   ],
   "source": [
    "device_id = 0\n",
    "device = ttnn.open_device(device_id=device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2af6b5f-8f8a-47ab-bb52-427324d88341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttnn.Tensor([    2,     3,  ...,     5,     1], shape=Shape([4]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR)\n"
     ]
    }
   ],
   "source": [
    "# first we need to create an input tensor - this is just tokens. let's make some random stuff\n",
    "\n",
    "input_tensor_ttnn = ttnn.from_torch(input_ids, dtype=ttnn.uint32, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "\n",
    "print(input_tensor_ttnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19dec1b1-2c85-4a0b-834c-9350e6903794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[-2.14062,  1.05469, -1.21875],\n",
       "             [ 1.31250,  1.05469,  0.13867],\n",
       "             ...,\n",
       "             [ 0.18359,  0.22949,  0.61719],\n",
       "             [-0.28711,  0.82031,  0.15137]], shape=Shape([6, 3]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next we need an initialization of random weight matrices:\n",
    "weight_torch = torch.randn(vocab_size, output_dim)\n",
    "weight_torch\n",
    "\n",
    "weight_ttnn = ttnn.from_torch(weight_torch, dtype=ttnn.bfloat16, device=device)\n",
    "weight_ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a44499d9-9ab6-498b-8cc4-5bb0ddece619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[-0.20410, -2.26562, -0.91406],\n",
       "             [-0.41992, -0.66016, -0.79688],\n",
       "             ...,\n",
       "             [-0.28711,  0.82031,  0.15137],\n",
       "             [ 1.31250,  1.05469,  0.13867]], shape=Shape([4, 3]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_ttnn = ttnn.embedding(input_tensor_ttnn, weight_ttnn)\n",
    "embedding_ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44b27758-b9ee-44db-aba6-77094aa62ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[-0.20410, -2.26562, -0.91406],\n",
       "             [-0.41992, -0.66016, -0.79688],\n",
       "             ...,\n",
       "             [-0.28711,  0.82031,  0.15137],\n",
       "             [ 1.31250,  1.05469,  0.13867]], shape=Shape([4, 3]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = ttnn.from_device(embedding_ttnn)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35265242-daa1-4af9-9f8f-8d7f976299c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Metal | INFO     | Closing device 0\n",
      "                  Metal | INFO     | Disabling and clearing program cache on device 0\n"
     ]
    }
   ],
   "source": [
    "ttnn.close_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d827ad60-bb9c-4fef-a24f-fe6c7df646e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ttnn.Tensor([[-0.20410, -2.26562, -0.91406],\n",
       "             [-0.41992, -0.66016, -0.79688],\n",
       "             ...,\n",
       "             [-0.28711,  0.82031,  0.15137],\n",
       "             [ 1.31250,  1.05469,  0.13867]], shape=Shape([4, 3]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that output on CPu is equivalent to : embedding_layer(input_ids) in torch\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8bc46fa-eaa7-41be-bab1-62335a72a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_view(ttnn_tensor, seq_len, out_dim):\n",
    "    rm = ttnn.to_layout(ttnn_tensor, ttnn.ROW_MAJOR_LAYOUT)\n",
    "    cpu = ttnn.to_torch(rm)\n",
    "    return cpu[:, :seq_len, :out_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21aaaf96-a212-4ad7-aebc-48b81889f8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Metal | INFO     | Initializing device 0. Program cache is NOT enabled\n",
      "                  Metal | INFO     | AI CLK for device 0 is:   1000 MHz\n",
      "TOKEN_EMBEDDING TTNN ttnn.Tensor([[[ 0.42383,  0.27930,  ...,  0.43359, -1.03125],\n",
      "              [-0.94141,  3.17188,  ...,  0.85938,  1.13281],\n",
      "              ...,\n",
      "              [-0.14160,  0.51953,  ..., -0.86719,  0.89062],\n",
      "              [-0.72266,  0.56641,  ...,  1.31250,  0.19043]],\n",
      "\n",
      "             [[-0.82031, -0.33594,  ..., -1.05469, -1.54688],\n",
      "              [ 1.17969, -0.96875,  ..., -0.21387,  0.09814],\n",
      "              ...,\n",
      "              [-0.40430,  0.41797,  ..., -1.25000,  0.73047],\n",
      "              [-0.43164, -0.83594,  ...,  1.38281, -0.69531]],\n",
      "\n",
      "             ...,\n",
      "\n",
      "             [[-0.87109,  0.05957,  ..., -0.64062, -0.57031],\n",
      "              [-0.36523,  0.61328,  ..., -0.84375, -0.32031],\n",
      "              ...,\n",
      "              [-0.23340,  2.00000,  ..., -0.04639,  0.44141],\n",
      "              [-0.85938, -0.04541,  ...,  0.37500, -0.79297]],\n",
      "\n",
      "             [[-0.23340,  2.00000,  ..., -0.04639,  0.44141],\n",
      "              [-0.74609, -0.46875,  ..., -0.43164,  0.84375],\n",
      "              ...,\n",
      "              [-0.41211,  0.81641,  ...,  0.19824, -0.46094],\n",
      "              [ 0.87109, -0.37500,  ..., -0.44336,  0.73828]]], shape=Shape([8, 4, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)\n",
      "POSITION TTNN ttnn.Tensor([[-1.10938,  1.05469,  ...,  0.52344,  0.62109],\n",
      "             [-2.53125, -0.55078,  ..., -0.64062, -0.22656],\n",
      "             ...,\n",
      "             [ 0.41602, -0.10449,  ...,  1.35156,  1.14844],\n",
      "             [ 0.18262,  0.33398,  ...,  2.54688, -1.14844]], shape=Shape([4, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: reader_unary_stick_layout_split_rows_interleaved\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: writer_unary_interleaved_start_id, reader_unary_stick_layout_split_rows_interleaved, tilize\n",
      "ttnn.Tensor([[[-0.68750,  1.33594,  ...,  0.95703, -0.41016],\n",
      "              [-3.46875,  2.62500,  ...,  0.21875,  0.90625],\n",
      "              ...,\n",
      "              [ 0.27539,  0.41602,  ...,  0.48438,  2.04688],\n",
      "              [-0.53906,  0.90234,  ...,  3.85938, -0.95703]],\n",
      "\n",
      "             [[-1.92969,  0.71875,  ..., -0.53125, -0.92578],\n",
      "              [-1.35156, -1.52344,  ..., -0.85547, -0.12891],\n",
      "              ...,\n",
      "              [ 0.01172,  0.31445,  ...,  0.10156,  1.88281],\n",
      "              [-0.24902, -0.50391,  ...,  3.93750, -1.84375]],\n",
      "\n",
      "             ...,\n",
      "\n",
      "             [[-1.98438,  1.11719,  ..., -0.11719,  0.05078],\n",
      "              [-2.89062,  0.06250,  ..., -1.48438, -0.54688],\n",
      "              ...,\n",
      "              [ 0.18262,  1.89844,  ...,  1.30469,  1.59375],\n",
      "              [-0.67578,  0.28906,  ...,  2.92188, -1.94531]],\n",
      "\n",
      "             [[-1.34375,  3.06250,  ...,  0.47656,  1.06250],\n",
      "              [-3.28125, -1.02344,  ..., -1.07031,  0.61719],\n",
      "              ...,\n",
      "              [ 0.00391,  0.71094,  ...,  1.54688,  0.68750],\n",
      "              [ 1.05469, -0.04102,  ...,  2.10938, -0.41016]]], shape=Shape([8, 4, 256]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: reader_unary_interleaved_start_id\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 16. First unused index: 1. Kernels: writer_unary_stick_layout_split_rows_interleaved, reader_unary_interleaved_start_id, pack_untilize\n",
      "                  Metal | INFO     | Closing device 0\n",
      "                  Metal | INFO     | Disabling and clearing program cache on device 0\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "# Open the device\n",
    "device_id = 0\n",
    "device = ttnn.open_device(device_id=device_id)\n",
    "\n",
    "# Get the next batch of inputs and targets. This should be a shape of (8, 4)\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "# Next let's convert these to be ttnn tensor friendly and send to hardware\n",
    "inputs_ttnn = ttnn.to_device(to_ttnn_batch(inputs, device=device), device)\n",
    "targets_ttnn = ttnn.to_device(to_ttnn_batch(targets, device=device), device=device)\n",
    "\n",
    "# We will now create the token embedding matrix.\n",
    "# Create randomized weight matrix first \n",
    "weight_ttnn = ttnn.to_device(\n",
    "    ttnn.from_torch(\n",
    "        torch.randn(vocab_size, output_dim),\n",
    "        dtype=ttnn.bfloat16,\n",
    "        layout=ttnn.ROW_MAJOR_LAYOUT\n",
    "    ),\n",
    "    device\n",
    ")\n",
    "\n",
    "# create the token_embedding matrix with weight_ttnn and inputs_ttnn using ttnn.embedding\n",
    "# the result should be (8, 4, 256)\n",
    "token_embedding_ttnn = ttnn.embedding(inputs_ttnn, weight_ttnn)\n",
    "print(\"TOKEN_EMBEDDING TTNN\", token_embedding_ttnn)\n",
    "\n",
    "# Next, create the positional embedding matrix. this should end up being (4, 256)\n",
    "# First, we need to create the randomized weights\n",
    "context_length = max_length\n",
    "pos_weight_ttnn = ttnn.to_device(\n",
    "    ttnn.from_torch(\n",
    "        torch.randn(context_length, output_dim),\n",
    "        dtype=ttnn.bfloat16,\n",
    "        layout=ttnn.ROW_MAJOR_LAYOUT\n",
    "    ),\n",
    "    device\n",
    ")\n",
    "\n",
    "# Create the positional inputs matrix\n",
    "pos_input_ttnn = ttnn.to_device(ttnn.arange(end=max_length, dtype=ttnn.uint32), device)\n",
    "\n",
    "# finally create the positional embedding matrix\n",
    "pos_embedding_ttnn = ttnn.embedding(pos_input_ttnn, pos_weight_ttnn)\n",
    "print(\"POSITION TTNN\", pos_embedding_ttnn)\n",
    "\n",
    "# Combine the token embeddings and positional embeddings to create the input embeddings\n",
    "pos_embedding_ttnn = ttnn.reshape(pos_embedding_ttnn, (1, 4, 256))\n",
    "pos_embedding_ttnn = ttnn.repeat_interleave(pos_embedding_ttnn, repeats=8, dim=0)\n",
    "input_embeddings_ttnn = ttnn.add(ttnn.tilize(token_embedding_ttnn), ttnn.tilize(pos_embedding_ttnn))\n",
    "\n",
    "print(ttnn.untilize(input_embeddings_ttnn))\n",
    "\n",
    "ttnn.close_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c00c8-8c7a-47dd-ac8c-6de4c2776308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf733e1e-df96-40ee-8adb-6d4309e231f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
