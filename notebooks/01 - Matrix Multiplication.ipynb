{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a248af9f-46f4-403c-8280-93999632d774",
   "metadata": {},
   "source": [
    "# Matrix Multiplication Demo\n",
    "\n",
    "Quick demo to show how to multiply 2 matrices on the device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360584d-61dc-403f-8161-69f0e2d01e4d",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import `torch` and `ttnn`. The paradigm here for this demo is that if we're on a CUDA card, we use `torch` to build our data, and then send to the CUDA device when we're ready. `torch` has built in capabilities for handling CUDA devices, but not Tenstorrent devices. That's why we use `ttnn` library. `ttnn` helps us send our tensors to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ebfa29-091a-459b-a4f0-481ad974bf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 07:28:15.040 | DEBUG    | ttnn:<module>:83 - Initial ttnn.CONFIG:\n",
      "Config{cache_path=/home/avgdev/.cache/ttnn,model_cache_path=/home/avgdev/.cache/ttnn/models,tmp_dir=/tmp/ttnn,enable_model_cache=false,enable_fast_runtime_mode=true,throw_exception_on_fallback=false,enable_logging=false,enable_graph_report=false,enable_detailed_buffer_report=false,enable_detailed_tensor_report=false,enable_comparison_mode=false,comparison_mode_should_raise_exception=false,comparison_mode_pcc=0.9999,root_report_path=generated/ttnn/reports,report_name=std::nullopt,std::nullopt}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ttnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fe82c-3a58-45d4-806e-ef98a83c707d",
   "metadata": {},
   "source": [
    "## Create Tensors\n",
    "\n",
    "Notice creating tensors is the same as always with `torch`. We just need to convert them to `ttnn` tensors by using `from_torch`. More details on `TILE_LAYOUT` later, but just know that the Wormhole n150d has a different memory access pattern than `torch`. (tile-based access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8483daea-0a93-4b15-8bc5-af5e4977fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[3, 3]])\n",
    "b = torch.tensor([[2], [5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b370d72-b47b-47f2-b6c6-9b949e50bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ttnn.from_torch(a, dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT)\n",
    "b = ttnn.from_torch(b, dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1733aa2-b9a9-486e-803b-6ab6c13cdca4",
   "metadata": {},
   "source": [
    "## Opening the Device\n",
    "\n",
    "Here it is! You communicate with the device. It's just as simple as finding the device id (most of the time, `0`) and using `open_device` with the `device_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e41a2168-b401-4c4e-8675-5aaeb29bb887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Device | INFO     | Opening user mode device driver\n",
      "\u001b[32m2025-04-19 07:28:18.654\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\n",
      "\u001b[32m2025-04-19 07:28:18.667\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-04-19 07:28:18.669\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Harvesting mask for chip 0 is 0x200 (physical layout: 0x1, logical: 0x200, simulated harvesting mask: 0x0).\n",
      "\u001b[32m2025-04-19 07:28:18.670\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Opened PCI device 0; KMD version: 1.33.0, IOMMU: disabled\n",
      "\u001b[32m2025-04-19 07:28:18.671\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected PCI devices: [0]\n",
      "\u001b[32m2025-04-19 07:28:18.671\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using local chip ids: {0} and remote chip ids {}\n",
      "\u001b[32m2025-04-19 07:28:18.694\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Software version 6.0.0, Ethernet FW version 6.14.0 (Device 0)\n",
      "                  Metal | INFO     | Initializing device 0. Program cache is NOT enabled\n",
      "                  Metal | INFO     | AI CLK for device 0 is:   1000 MHz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New chip! We now have 1 chips\n",
      "Chip initialization complete (found )\n",
      "Chip initializing complete...\n",
      " ARC\n",
      "\n",
      " [4/4] DRAM\n",
      "\n",
      " [16/16] ETH\n",
      "\n",
      " CPU\n",
      "\n",
      "Chip detection complete (found )\n"
     ]
    }
   ],
   "source": [
    "device_id = 0\n",
    "device = ttnn.open_device(device_id=device_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551b969-98d7-4a57-b9d7-c2662f349cb8",
   "metadata": {},
   "source": [
    "## Send to the Device and Operate\n",
    "\n",
    "Just like `torch` can send tensors to the CUDA device, you can send `ttnn` tensors to the Tenstorrent device. \n",
    "\n",
    "Straightforward here, you can use `matmul` to compute the result once you have those tensors in. `output` lives in the device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b40dd6af-0c70-45f9-b586-092e6bf5daa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 4,5. First unused index: 2. Kernels: reader_bmm_tile_layout_in1_sender_writer_padding, reader_bmm_tile_layout_in0_sender_padding, bmm_large_block_zm_fused_bias_activation\n"
     ]
    }
   ],
   "source": [
    "a = ttnn.to_device(a, device)\n",
    "b = ttnn.to_device(b, device)\n",
    "\n",
    "output = ttnn.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759537ca-788a-4e20-a2ec-d3be4e442bcb",
   "metadata": {},
   "source": [
    "## Check the Result\n",
    "\n",
    "Print and assert..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76a7628-e389-4752-b928-90b05309cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape([1, 1]), DataType.BFLOAT16, ttnn.Tensor([[21.00000]], shape=Shape([1, 1]), dtype=DataType::BFLOAT16, layout=Layout::TILE)\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 2. First unused index: 1. Kernels: reader_unary_interleaved_start_id\n",
      "                  Metal | WARNING  | Circular buffer indices are not contiguous starting at 0. This will hurt dispatch performance. Non-contiguous indices: 2. First unused index: 1. Kernels: writer_unary_interleaved_start_id, reader_unary_interleaved_start_id, eltwise_sfpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"{output.shape}, {output.dtype}, {output}\")\n",
    "\n",
    "assert output[0] == 21.0000\n",
    "assert output.shape == [1, 1]\n",
    "assert output.dtype == ttnn.bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa87b85d-6efc-4faa-9a81-e1314a85f323",
   "metadata": {},
   "source": [
    "## Sending the Result back to Host\n",
    "\n",
    "Here, we demonstrate how we can move the `output` tensor back to the host computer (CPU memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a18dd1-8707-4a3a-9f2e-6451309297e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cpu = ttnn.from_device(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5678eb-574e-4ca8-8f6d-e18971907892",
   "metadata": {},
   "source": [
    "Same as before, we validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c024d76c-7542-4cb5-a7be-759818065be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttnn.Tensor([[21.00000]], shape=Shape([1, 1]), dtype=DataType::BFLOAT16, layout=Layout::TILE)\n"
     ]
    }
   ],
   "source": [
    "print(output_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf63eb-eb21-4911-be5b-58eb2d15b59b",
   "metadata": {},
   "source": [
    "## Close the Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c5e1c6-11eb-4d11-a69d-d35f1d3c870c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Metal | INFO     | Closing device 0\n",
      "                  Metal | INFO     | Disabling and clearing program cache on device 0\n"
     ]
    }
   ],
   "source": [
    "ttnn.close_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc75a0-c6cf-44df-a46c-1445c5c6b53f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
